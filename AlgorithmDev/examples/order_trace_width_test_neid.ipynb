{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import math\n",
    "from scipy import ndimage, misc\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "import csv\n",
    "import pickle\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import colors\n",
    "%matplotlib inline\n",
    "power = 3\n",
    "power_dir = \"output_neid_test_cluster_form2\"\n",
    "#power_dir = \"output_poly3_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlgorithmDev import OrderTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: spectral fits is from dropbox KPF-Pipeline-TestData/order_trace_test\n",
    "spectral_fits='../test_data/order_trace_test/DATA/paras.flatA.fits'\n",
    "\n",
    "# output\n",
    "clusters_collection = '../test_data/order_trace_test/'+power_dir+'/clusters_all_y_collection.pkl'\n",
    "cluster_xy_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_xy.fits'\n",
    "cluster_clean_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_clean.fits'\n",
    "cluster_info_clean_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_info_clean.fits'\n",
    "cluster_after_removal_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_after_removal.fits'\n",
    "cluster_info_after_removal_fits =  '../test_data/order_trace_test/'+power_dir+'/cluster_info_after_removal.fits'\n",
    "cluster_border_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_border.fits'\n",
    "cluster_info_border_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_info_border.fits'\n",
    "cluster_merge_fitting = '../test_data/order_trace_test/'+power_dir+'/cluster_merge_fitting.fits'\n",
    "cluster_info_merge_fitting = '../test_data/order_trace_test/'+power_dir+'/cluster_info_merging_fitting.fits'\n",
    "result_csv = '../test_data/order_trace_test/'+power_dir+'/result_cluster/result_cluster'\n",
    "result_poly_width_csv = '../test_data/order_trace_test/'+power_dir+'/output/paras_result_poly_2sigma_gaussian_pixel_'+str(power)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: spectral fits is from dropbox KPF-Pipeline-TestData/NEIData/FLAT\n",
    "spectral_fits='../test_data/order_trace_test/DATA/stacked_2fiber_flat.fits'\n",
    "\n",
    "# output\n",
    "clusters_collection = '../test_data/order_trace_test/'+power_dir+'/clusters_all_y_collection.pkl'\n",
    "remove_vertical_fits = '../test_data/order_trace_test/'+power_dir+'/data_remove_vertical.fits'\n",
    "cluster_xy_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_xy.fits'\n",
    "cluster_clean_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_clean.fits'\n",
    "cluster_info_clean_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_info_clean.fits'\n",
    "cluster_after_removal_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_after_removal.fits'\n",
    "cluster_info_after_removal_fits =  '../test_data/order_trace_test/'+power_dir+'/cluster_info_after_removal.fits'\n",
    "cluster_border_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_border.fits'\n",
    "cluster_info_border_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_info_border.fits'\n",
    "cluster_merge_fitting = '../test_data/order_trace_test/'+power_dir+'/cluster_merge_fitting.fits'\n",
    "cluster_info_merge_fitting = '../test_data/order_trace_test/'+power_dir+'/cluster_info_merging_fitting.fits'\n",
    "result_csv = '../test_data/order_trace_test/'+power_dir+'/result_cluster/result_cluster'\n",
    "result_poly_width_csv = '../test_data/order_trace_test/'+power_dir+'/output/neid_result_poly_2sigma_gaussian_pixel_0221_'+str(power)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image from fits by setting area xmin, xmax, ymin, ymax\n",
    "def plot_img(img, ymin, ymax, p_w=20, p_h=20, xmin=None, xmax=None, title=\"\", aspect=None):\n",
    "    plt.figure(figsize=(p_w, p_h), frameon=False)\n",
    "    plt.subplot(1, 1, 1)\n",
    "    if xmin is None:\n",
    "        xmin = 0\n",
    "    if xmax is None:\n",
    "        h, w = np.shape(img)\n",
    "        xmax = w-1\n",
    "    s_img = img[:, :]\n",
    "    im = plt.imshow(s_img, cmap='gray', norm=LogNorm())\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.title(title)\n",
    "    if aspect is not None:\n",
    "        plt.axes().set_aspect(aspect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image from fits by setting area xmin, xmax, ymin, ymax on top of another image\n",
    "# the top image could be image of set of clusters by using make_2D_data_range \n",
    "# background image in grey, and top image in red with 0.5 alpha in default. aspect is settable\n",
    "def plot_img_on_original(img, o_img, ymin, ymax, xmin=None, xmax=None, p_w=20, p_h=20, title=\"\", alpha = 0.5, aspect=None):\n",
    "    plt.figure(figsize=(p_w, p_h), frameon=False)\n",
    "    plt.subplot(1, 1, 1)\n",
    "    if xmin is None:\n",
    "        xmin = 0\n",
    "    if xmax is None:\n",
    "        h, w = np.shape(img)\n",
    "        xmax = w-1\n",
    "\n",
    "    cmap = colors.ListedColormap(['white', 'red'])    \n",
    "    im_b = plt.imshow(o_img, cmap='gray', norm=LogNorm())\n",
    "    im_t = plt.imshow(img, cmap=cmap, alpha=alpha) \n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.title(title)\n",
    "    if aspect is not None:\n",
    "        plt.axes().set_aspect(aspect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fits(data, output_fits):\n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    hdu.writeto(output_fits, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cluster width and height histogram information on selected clusters or all clusters\n",
    "def show_cluster_info(index, x, y, nx, ny, selected_clusters=None):\n",
    "    widths = list()\n",
    "    heights = list()\n",
    "    good_widths = list()\n",
    "    \n",
    "    widths.append(0)\n",
    "    heights.append(0)\n",
    "    \n",
    "    #print('selected_clusters: ', selected_clusters)\n",
    "    #import pdb;pdb.set_trace() \n",
    "    \n",
    "    for sc in selected_clusters:\n",
    "        idx = np.where(index==sc)[0]\n",
    "        sel_x = x[idx]\n",
    "        sel_y = y[idx]\n",
    "        x1 = np.amin(sel_x)\n",
    "        x2 = np.amax(sel_x)\n",
    "        y1 = np.amin(sel_y)\n",
    "        y2 = np.amax(sel_y)\n",
    "        w = x2 - x1 + 1\n",
    "        h = y2 - y1 + 1\n",
    "        if sc%100 == 0:\n",
    "            print('cluster: ', sc, ' total pixels: ', np.size(sel_x), ' x1, x2, y1, y2: ',\n",
    "                 x1, x2, y1, y2, ' w, h: ', w, h)   \n",
    "        widths.append(w)\n",
    "        heights.append(h)\n",
    "        if w >= nx/4:\n",
    "            good_widths.append(sc)\n",
    "        \n",
    "    #import pdb;pdb.set_trace() \n",
    "    h_stats = order_t.find_cluster_stats_from_histogram(np.array(heights), 10)\n",
    "    w_stats = order_t.find_cluster_stats_from_histogram(np.array(widths), 10)\n",
    "\n",
    "    for h_s in h_stats:\n",
    "        print('height stats: ', h_s)\n",
    "    print('\\n')    \n",
    "    for w_s in w_stats:    \n",
    "        print('widthw stats: ', w_s)\n",
    "    #print('good_widths: ', good_widths)\n",
    "    \n",
    "    return h_stats, w_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cluster size information for each cluster from selected cluster\n",
    "def show_cluster_size(index, x, y, nx, ny, selected_clusters=None):\n",
    "    if selected_clusters is None:\n",
    "        selected_cluseters = np.arange(1, np.amax(index)+1, dtype=int)\n",
    "    for i in selected_clusters:\n",
    "        cluster_idx = np.where(index == i)[0]\n",
    "        x1 = np.amin(x[cluster_idx])\n",
    "        x2 = np.amax(x[cluster_idx])\n",
    "        y1 = np.amin(y[cluster_idx])\n",
    "        y2 = np.amax(y[cluster_idx])\n",
    "        #import pdb;pdb.set_trace()\n",
    "        \n",
    "        print('cluster ', i, ' total: ', np.size(cluster_idx), \" width: \", (x2-x1+1), \" height: \", (y2-y1+1))\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image data in 2D based on selected clusters\n",
    "def make_2D_data(index, x, y, nx, ny, selected_clusters=None):\n",
    "    imm = np.zeros((ny, nx), dtype=np.uint8)\n",
    "    if selected_clusters is None:\n",
    "        ymin = 0\n",
    "        ymax = ny-1\n",
    "    else:\n",
    "        sel = np.where(np.isin(index, selected_clusters))[0]\n",
    "        ymin = np.amin(y[sel])\n",
    "        ymax = np.amax(y[sel])\n",
    "                       \n",
    "    for cy in range(ny):\n",
    "        if cy < ymin: \n",
    "            continue\n",
    "        elif cy > ymax:\n",
    "            break;\n",
    "        #print(cy,' ', end='')    \n",
    "        y_cond = np.where(y==cy)[0]\n",
    "        if selected_clusters is None:\n",
    "            nz_idx_at_cy = y_cond[np.where(index[y_cond] != 0)[0]]\n",
    "        else:\n",
    "            nz_idx_at_cy = y_cond[np.where(np.isin(index[y_cond], selected_clusters))[0]]\n",
    "        imm[cy, x[nz_idx_at_cy]] = 1\n",
    "    print()    \n",
    "\n",
    "    return imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image data in 2D based on selected clusters and return image and range\n",
    "def make_2D_data_range(index, x, y, nx, ny, selected_clusters=None):\n",
    "    imm = np.zeros((ny, nx), dtype=np.uint8)\n",
    "    xmin = nx\n",
    "    xmax = 0\n",
    "\n",
    "    if selected_clusters is None:\n",
    "        ymin = 0\n",
    "        ymax = ny-1\n",
    "    else:\n",
    "        sel = np.where(np.isin(index, selected_clusters))[0]\n",
    "        ymin = np.amin(y[sel])\n",
    "        ymax = np.amax(y[sel])\n",
    "        xmin = np.amin(x[sel])\n",
    "        xmax = np.amax(x[sel])\n",
    "                       \n",
    "    print('y: ', ymin, ymax)    \n",
    "    for cy in range(ny):\n",
    "        if cy < ymin: \n",
    "            continue\n",
    "        elif cy > ymax:\n",
    "            break;\n",
    "\n",
    "        y_cond = np.where(y==cy)[0]\n",
    "        if selected_clusters is None:\n",
    "            nz_idx_at_cy = y_cond[np.where(index[y_cond] != 0)[0]]\n",
    "        else:\n",
    "            nz_idx_at_cy = y_cond[np.where(np.isin(index[y_cond], selected_clusters))[0]]\n",
    "       \n",
    "        imm[cy, x[nz_idx_at_cy]] = 1\n",
    "    print()    \n",
    "\n",
    "    return imm, xmin, xmax, ymin, ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fits on 2D of all clusters\n",
    "def make_cluster_fits(index, x, y, nx, ny, fits_path):\n",
    "    imm = make_2D_data(index, x, y,  nx, ny)\n",
    "    make_fits(imm, fits_path)\n",
    "    ind_max = np.amax(index)\n",
    "    print('there are '+str(ind_max)+' clusters in total in fits, '+fits_path)\n",
    "    return imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fits on cluster info (index, x, y)\n",
    "def make_cluster_info_fits(index, x, y, cluster_info_filepath):\n",
    "    cluster_data = np.zeros((3, index.size))\n",
    "    cluster_data[0, :] = index\n",
    "    cluster_data[1, :] = x\n",
    "    cluster_data[2, :] = y\n",
    "    make_fits(cluster_data, cluster_info_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt filter by given y data of a column \n",
    "def opt_filter(y_data, par=20, weight=None):      \n",
    "    n = y_data.size\n",
    "    #import pdb; pdb.set_trace()\n",
    "    # 1D array\n",
    "    if y_data.ndim != 1:\n",
    "        print('opt_filter handles one dimensional y data only')\n",
    "        return y_data\n",
    "\n",
    "    if par < 0:\n",
    "        return y_data\n",
    "\n",
    "    wgt = np.reshape(weight, (1, -1)) if weight is not None else np.ones((1, n), dtype=np.float64)[0]\n",
    "\n",
    "    r = y_data*wgt\n",
    "    \n",
    "    # resolve banded matrix by combining a, b, c, abc*f = r\n",
    "    a = np.ones((1, n), dtype=np.float64)[0] * (-abs(par))\n",
    "    b = np.hstack([[wgt[0]+abs(par)], wgt[1:n-1]+2.0*abs(par), [wgt[n-1]+abs(par)]])\n",
    "    c = a.copy()\n",
    "    a[0] = c[-1] = 0\n",
    "    B = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        B[i, i] = b[i]\n",
    "        if i != n-1:\n",
    "            B[i+1, i] = c[i]\n",
    "            B[i, i+1] = a[i+1]\n",
    "            \n",
    "    BINV = linalg.inv(B)\n",
    "    f = linalg.solve_banded((1, 1), np.vstack([a, b, c]), r)\n",
    "    return f, B, BINV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blockprint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "def enable_print():\n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot polynomial fitting curve on top of given 2D image\n",
    "# the cluster orders is settable by order_set\n",
    "def plot_poly_trace(imm, total_order, coeffs_orders, max_x, max_y, size=20, order_set=None, \\\n",
    "                    title=None, background=False, widths=None, aspect=None, xmin=None, xmax=None, ymin=None, ymax=None):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    im = plt.imshow(imm, cmap='gray', norm=LogNorm())\n",
    "    \n",
    "    if order_set is None:\n",
    "        orders = list(range(1, total_order+1))\n",
    "    else:\n",
    "        orders = order_set\n",
    "        \n",
    "    x_dist = max_x//20    \n",
    "                   \n",
    "    for o_idx, order in enumerate(orders):\n",
    "        if (background is not False):\n",
    "            x_val = np.arange(0, max_x)\n",
    "            # y value on x range\n",
    "            y_val = np.polyval(coeffs_orders[order, 0:power+1], x_val)\n",
    "            plt.plot(x_val, y_val, 'b--')\n",
    "        #print(\"x range: \", coeffs_orders[order, power+1], coeffs_orders[order, power+2])    \n",
    "        # x range\n",
    "        x_val = np.arange(coeffs_orders[order, power+1], coeffs_orders[order, power+2]+1)\n",
    "        # y value on x range\n",
    "        y_val = np.polyval(coeffs_orders[order, 0:power+1], x_val)\n",
    "        plt.plot(x_val, y_val, 'r--')\n",
    "        \n",
    "        if widths is not None:\n",
    "            y_val_bottom = y_val-widths[o_idx][0]\n",
    "            plt.plot(x_val, y_val_bottom, 'g--')\n",
    "            y_val_top = y_val+widths[o_idx][1]\n",
    "            plt.plot(x_val, y_val_top, 'g--')\n",
    "        \n",
    "        # show number of cluster\n",
    "        s = ((order%15)+1)*x_dist\n",
    "        if s >= x_val.size:\n",
    "            dem = int((coeffs_orders[order, power+2] - coeffs_orders[order, power+1])//5)\n",
    "            s = dem*((order%4)+1)\n",
    "            #s = x_val.size//2\n",
    "        plt.text(x_val[s], y_val[s], str(order), fontsize=12, color='b', fontweight='bold', horizontalalignment='center', verticalalignment='center')\n",
    "        \n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=12)\n",
    "    x1 = 0 if xmin is None else xmin\n",
    "    x2 = max_x if xmax is None else xmax\n",
    "    y1 = 0 if ymin is None else ymin\n",
    "    y2 = max_y if ymax is None else ymax\n",
    "    \n",
    "    plt.ylim(y1, y2)\n",
    "    plt.xlim(x1, x2)\n",
    "    if aspect is not None:\n",
    "        plt.axes().set_aspect(aspect)\n",
    "    \n",
    "    plt.show()\n",
    "    #plt.colorbar(im, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot y value from min_y to max_y at each x location from min_x to max_x\n",
    "def plot_data_at_x(data, min_x, max_x, min_y, max_y, cluster_points, size=20, title=None, cluster_no=None, w1=None, w2=None, slope_set=None, slope=None, slope_double=None):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    display_color = ['r', 'b', 'k', 'g', 'y', 'm', 'c']\n",
    "    size = np.shape(data)\n",
    "    \n",
    "    # min_y to max_y set to be value on x axis. \n",
    "    plt_x_val = np.arange(0, size[0]) + min_y   \n",
    "    \n",
    "    #print(cluster_no)\n",
    "    #import pdb;pdb.set_trace()\n",
    "    for x in range(min_x, max_x+1):      \n",
    "        d_idx = (x - min_x)%(len(display_color))\n",
    "        plt_y_val = data[:, x]\n",
    "        plt.plot(plt_x_val, plt_y_val, lineStyle='--', marker='o', color=display_color[d_idx])\n",
    "        cluster_data = cluster_points[:, x]\n",
    "        cluster_data = cluster_data[np.where(np.logical_and(cluster_data <= max_y, cluster_data >= min_y))[0]]\n",
    "        \n",
    "        # put dots on peak and the width around the peak of the cluster with cluster_no\n",
    "        if cluster_data.size > 0:\n",
    "            cluster_data_y = np.zeros(cluster_data.size)                    \n",
    "            plt.scatter(cluster_data, cluster_data_y, c=display_color[d_idx][0])   \n",
    "            if cluster_no != None and w1!= None and w2 != None:\n",
    "                cluster_y = cluster_points[cluster_no][x]\n",
    "                dots = np.zeros(1)\n",
    "                plt.scatter(np.array([cluster_y]), dots, c='k', alpha=0.5)\n",
    "                cluster_x1 = cluster_y - w1\n",
    "                cluster_x2 = cluster_y + w2\n",
    "                dots = np.zeros(2)\n",
    "                plt.scatter(np.array([cluster_x1, cluster_x2]), dots, c='b', alpha=0.5)\n",
    "                \n",
    "            \n",
    "        if slope is not None:\n",
    "            slope_at_x = slope[:, x - min_x]\n",
    "            plt.plot(plt_x_val, slope_at_x, 'bo')\n",
    "        if slope_double is not None:\n",
    "            slope_2nd_at_x = slope_double[:, x - min_x]\n",
    "            plt.plot(plt_x_val, slope_2nd_at_x, 'g-')\n",
    "        if slope_set is not None:\n",
    "            for i in range(len(slope_set)):\n",
    "                #import pdb;pdb.set_trace()\n",
    "                y_val = None\n",
    "                if 'coeffs' in slope_set[i]:\n",
    "                    slope_coeffs = slope_set[i]['coeffs']\n",
    "                    bound = slope_set[i]['bound']\n",
    "                    x_set = np.arange(bound[0], bound[1]+1)\n",
    "                    y_val = np.polyval(slope_coeffs, x_set)\n",
    "                elif 'gaussian' in slope_set[i] and slope_set[i]['gaussian'] is not None:\n",
    "                    x_set = slope_set[i]['x_set']\n",
    "                    y_val = slope_set[i]['gaussian'](x_set)\n",
    "                    \n",
    "                if y_val is not None:    \n",
    "                    plt.plot(x_set, y_val, 'k-')\n",
    "                #plt.plot([x_set[0], x_set[0]], [0, y_val[0]], 'k--')\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=14)\n",
    "    plt.xlim(min_y, max_y)    \n",
    "    plt.show()\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show curve fitting on given x & y data by using polynomial\n",
    "def curve_fitting_plot(x_data, y_data, pow = 3, size=12, extend=1500):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    curve_coeffs = np.polyfit(x_data, y_data, pow)\n",
    "    \n",
    "    x_min = int(np.amin(x_data)) - extend\n",
    "    x_max = int(np.amax(x_data)) + extend\n",
    "    \n",
    "    plt_x_val = np.arange(x_min, x_max)\n",
    "    plt_y_val = np.polyval(curve_coeffs, plt_x_val)\n",
    "    \n",
    "    \n",
    "    plt.plot(x_data, y_data, 'r+')\n",
    "    plt.plot(plt_x_val, plt_y_val, c='b')\n",
    "    \n",
    "    #import pdb;pdb.set_trace()\n",
    "    roots = np.roots(curve_coeffs)\n",
    "    der_coeffs = np.polyder(curve_coeffs)\n",
    "    roots_der = np.roots(der_coeffs)\n",
    "    \n",
    "    plt.title('order: '+str(pow)+ ' extreme: '+str(roots_der.real),\n",
    "               fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(afloat):\n",
    "    new_str = f\"{afloat:.4f}\"\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json save and load\n",
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the following set of two plots along the entire x axis range (~ every 2000 pixels for each set on NEID data):\n",
    "#  1. plot the trace of selected clusters plus the the trace at top width and bottom width location (optional)\n",
    "#  2. plot the image of selected clusters on top of the original image\n",
    "def plot_selected_clusters_on_original_img(s_clusters, n_x, n_y, n_index, n_coeffs, show_width=False, alpha=0.5):\n",
    "    print(s_clusters)\n",
    "    \n",
    "    sel_imm, xmin, xmax, ymin, ymax = make_2D_data_range(n_index, n_x, n_y, nx, ny, selected_clusters=s_clusters)\n",
    "    imm_spec = spe_info['data']\n",
    "    print('range: ', xmin, xmax, ymin, ymax)\n",
    "    \n",
    "    max_index = np.amax(n_index)\n",
    "    a = 3         # aspect\n",
    "    y_off = 20    # vertical offset added to the range\n",
    "    step = (nx+5)//4   # split the display into parts\n",
    "    \n",
    "    if show_width is True:\n",
    "        cluster_points = order_t.get_cluster_points(n_coeffs, power)\n",
    "        all_widths = order_t.find_all_cluster_widths(n_index, n_x, n_y, \\\n",
    "                                    n_coeffs, cluster_points, power, cluster_set=s_clusters)\n",
    "        c_widths = [[one_width['avg_pwidth'], one_width['avg_nwidth']] for one_width in all_widths]\n",
    "        print('widths: ', c_widths)\n",
    "    else:\n",
    "        c_widths = None\n",
    "        \n",
    "    for x in range(0, nx, step):\n",
    "        x1 = x\n",
    "        x2 = min(x+step, xmax)\n",
    "        \n",
    "        # print trace on top of original image\n",
    "        plot_poly_trace(imm_spec, max_index, n_coeffs, nx, ny, widths = c_widths, \n",
    "                        order_set=s_clusters, xmin=x1, xmax=x2, ymin=ymin-y_off, ymax=ymax+y_off, aspect=a)\n",
    "        # plot image of selected clusters on top of orignal image\n",
    "        plot_img_on_original(sel_imm, imm_spec, ymin-y_off, ymax+y_off, xmin=x1, xmax=x2, \\\n",
    "                             p_w=20, p_h=20, alpha=alpha, aspect=a, title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menu to select cluster and plot the selected clusters\n",
    "def show_one_cluster_per_plot_menu(index_t, x, y, nx, ny):\n",
    "    select_idx = input(\"select a cluster to view: (ex: 10, from 1 to \"+ str(ind_max)+ \"):\\n\"+\n",
    "                    \"or a range of clusters to view: (ex: 6-10)\\n\" + \n",
    "                    \"or a set of clusters to view: (ex: 1, 2, 3)\\n\")\n",
    "    select_idx = select_idx.strip()\n",
    "    nums_set = select_idx.split(\",\")\n",
    "    num_set = list()\n",
    "\n",
    "    if (len(nums_set) > 1):\n",
    "        print(nums_set)\n",
    "        for nstr in nums_set:\n",
    "            if not nstr.isdigit():\n",
    "                print(nstr, \" is not a number\")\n",
    "            else:\n",
    "                num_set.append(int(nstr))\n",
    "    else:\n",
    "        nums_set = select_idx.split(\"-\")\n",
    "        print(nums_set)\n",
    "        if (len(nums_set) == 2):\n",
    "            if nums_set[0].isdigit() and nums_set[1].isdigit():\n",
    "                n1 = int(nums_set[0])\n",
    "                n2 = int(nums_set[1])\n",
    "                print(n1, n2)\n",
    "                if n1 > n2:\n",
    "                    n1, n2 = n2, n1\n",
    "                num_set = [i for i in range(n1, n2+1)]\n",
    "            else:\n",
    "                print(select_idx, \" is not valid number range\")\n",
    "        else:\n",
    "            if not select_idx.isdigit() or int(select_idx) < 0 or int(select_idx) > ind_max:\n",
    "                print(select_idx, \" is not a valid number\")\n",
    "            else:\n",
    "                num_set = [int(select_idx)]\n",
    "\n",
    "    print(num_set)        \n",
    "    num_selected = num_set[0]\n",
    "    if len(num_set) > 0:\n",
    "        num_set.sort()\n",
    "        for num_idx in num_set:\n",
    "            show_cluster_size(index_t, x, y, nx, ny, [num_idx])\n",
    "            new_imm = make_2D_data(index_t, x, y, nx, ny, [num_idx]) \n",
    "            sel = np.where(np.isin(index_t, [num_idx]))[0]\n",
    "\n",
    "            ymin = np.amin(y[sel])\n",
    "            ymax = np.amax(y[sel])\n",
    "            xmin = np.amin(x[sel])\n",
    "            xmax = np.amax(x[sel])\n",
    "\n",
    "            print('cluster: ', num_idx, 'x1, x2, y1, y2: ', xmin, xmax, ymin, ymax)    \n",
    "\n",
    "            plot_img(new_imm, ymin, ymax, 20, 20, xmin, xmax)\n",
    "            p_info, errors, area = order_t.extract_order_from_cluster(num_idx, index_t, x, y, power)\n",
    "            print(p_info, errors)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_clusters_per_plot_menu(index_t, x, y, nx, ny):\n",
    "    while(True):\n",
    "        select_idx = input(\"select clusters to view: all(A) \\n\" +\n",
    "                            \"exit(E) \\n\" + \n",
    "                            \"<one cluster>(cluster number)\\n\"+\n",
    "                            \"<multiple cluster>(No. 1, No. 2...)\\n\" + \n",
    "                            \"<cluster number range>(No. 1 - No. 2): \")\n",
    "        select_idx = select_idx.strip()\n",
    "\n",
    "        print(select_idx)\n",
    "\n",
    "        if select_idx == \"A\" or select_idx == \"a\":\n",
    "            plot_img(imm, 0, ny)\n",
    "            break\n",
    "        elif select_idx == \"E\" or select_idx == \"e\":\n",
    "            break\n",
    "        else:\n",
    "            nums_set = select_idx.split(\",\")\n",
    "            num_set = list()\n",
    "            if (len(nums_set) > 1):\n",
    "                for nstr in nums_set:\n",
    "                    if not nstr.isdigit():\n",
    "                        print(nstr, \" is not a number\")\n",
    "                        num_set = list()\n",
    "                        break\n",
    "                    else:\n",
    "                        num_set.append(int(nstr))\n",
    "                if len(num_set) > 1:\n",
    "                    print(num_set)\n",
    "                    num_set.sort()\n",
    "            else:\n",
    "                nums_set = select_idx.split(\"-\")\n",
    "                if (len(nums_set) == 2):\n",
    "                    if nums_set[0].isdigit() and nums_set[1].isdigit():\n",
    "                        n1 = int(nums_set[0])\n",
    "                        n2 = int(nums_set[1])\n",
    "                        if n1 > n2:\n",
    "                            n1, n2 = n2, n1\n",
    "                        num_set = [i for i in range(n1, n2+1)]\n",
    "                    else:\n",
    "                        print(select_idx, \" is not valid number range\")\n",
    "                else:\n",
    "                    if not select_idx.isdigit() or int(select_idx) < 0 or int(select_idx) > ind_max:\n",
    "                        print(select_idx, \" is not a valid number\")\n",
    "                    else:\n",
    "                        num_set = [int(select_idx)]\n",
    "\n",
    "            if len(num_set) == 0:\n",
    "                continue\n",
    "\n",
    "            #h_stats, w_stats = show_cluster_info(index_t, x, y, nx, ny, num_set)    \n",
    "            show_cluster_size(index_t, x, y, nx, ny, num_set)\n",
    "            new_imm = make_2D_data(index_t, x, y, nx, ny, num_set) \n",
    "            sel = np.where(np.isin(index_t, num_set))[0]\n",
    "\n",
    "            ymin = np.amin(y[sel])\n",
    "            ymax = np.amax(y[sel])\n",
    "            xmin = np.amin(x[sel])\n",
    "            xmax = np.amax(x[sel])\n",
    "\n",
    "            print('ymin: ', ymin, ' ymax: ', ymax, ' xmin: ', xmin, ' xmax: ', xmax)\n",
    "            #import pdb;pdb.set_trace()\n",
    "\n",
    "            # close up\n",
    "            plot_img(new_imm, ymin, ymax, 20, 20, xmin, xmax)\n",
    "            # full size\n",
    "            plot_img(new_imm, 0, ny-1, 20, 20)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage: Using OrderTarce to extract order trace from the given spectral fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "order_t = OrderTrace(spectral_fits)\n",
    "order_t.load_spectral()\n",
    "cluster_info = order_t.extract_order_trace(power)\n",
    "#result_poly_width_csv = '../test_data/order_trace_test/'+power_dir+'/result_poly_2sigma_gaussian_peak_'+str(power)+'.csv'\n",
    "order_t.write_cluster_info_to_csv(cluster_info['widths'], cluster_info['coeffs'], power, result_poly_width_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting order trace step by step\n",
    "### excute the cells from step 1 to step 10 and get visual output for each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load spectral file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_t = OrderTrace(spectral_fits)\n",
    "spe_info = order_t.load_spectral()\n",
    "print('row: ', spe_info['ny'], ' column: ', spe_info['nx'])\n",
    "\n",
    "imm_spec = spe_info['data']\n",
    "nx = spe_info['nx']\n",
    "ny = spe_info['ny']\n",
    "plot_img(imm_spec, 0, ny-1)\n",
    "#plot_img(imm_spec, 2000, 2100, xmin=4500, xmax=4600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. find cluster pixels  and make fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r_v = True if 'stacked_2fiber_flat' in spectral_fits else False\n",
    "\n",
    "cluster_xy = order_t.locate_clusters(remove_vertical = r_v)\n",
    "order_t.make_fits(cluster_xy['im_map'], cluster_xy_fits)\n",
    "yy = np.shape(cluster_xy['im_map'])[0]\n",
    "plot_img(cluster_xy['im_map'], 0, yy-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. form clusters, basic cleanning (based on size and total pixel), make fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cluster_info, dict\n",
    "cluster_info = order_t.collect_clusters(cluster_xy['x'], cluster_xy['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_collection = '../test_data/order_trace_test/'+power_dir+'/clusters_all_y_collection.pkl'\n",
    "save_obj(cluster_info, clusters_collection)   # optional, save cluster info into .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) load cluster collection \n",
    "cluster_info = load_obj(clusters_collection)   # optional, load cluster info from .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# assign index value to cluster_info['index'], where cluster_info['index'] is the same size as cluster_xy['x']\n",
    "cluster_info = order_t.remove_cluster_noise(cluster_info, cluster_xy['x'], cluster_xy['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unassigned index\n",
    "x, y, index_t = order_t.reorganize_index(cluster_info['index'], cluster_xy['x'], cluster_xy['y'])\n",
    "nx = spe_info['nx']\n",
    "ny = spe_info['ny']\n",
    "imm = order_t.make_2D_data(index_t, x, y)   # show image  and make fits and info fits \n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data from the result of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_t.make_fits(imm, cluster_clean_fits)\n",
    "\n",
    "cluster_data = np.zeros((3, index_t.size))\n",
    "cluster_data[0, :] = index_t\n",
    "cluster_data[1, :] = x\n",
    "cluster_data[2, :] = y\n",
    "order_t.make_fits(cluster_data, cluster_info_clean_fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reload clean fits and info fits of step 3. (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_clean_fits = '../test_data_backup/order_trace_test/'+power_dir+'/cluster_clean.fits'\n",
    "cluster_info_clean_fits = '../test_data_backup/order_trace_test/'+power_dir+'/cluster_info_clean.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) reload saved fits \n",
    "imm, hdr = fits.getdata(cluster_clean_fits, header=True)\n",
    "ny, nx = np.shape(imm)\n",
    "cluster_info, c_hdr = fits.getdata(cluster_info_clean_fits, header=True)\n",
    "index_t = cluster_info[0].astype(int)\n",
    "x = cluster_info[1].astype(int)\n",
    "y = cluster_info[2].astype(int)\n",
    "\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)\n",
    "ind_max = np.amax(index_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Advanced cluster cleaning to remove noisy clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index_new, all_status = order_t.advanced_cluster_cleaning_handler(index_t, x, y, power)\n",
    "\n",
    "# prepare for saving\n",
    "x_p = x.copy()\n",
    "y_p = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save advanced cleaning result of step 4 to fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save advanced cleaning result to fits and info fits\n",
    "#cluster_after_removal_fits = '../test_data/order_trace_test/'+power_dir+'/cluster_after_removal5.fits'\n",
    "#cluster_info_after_removal_fits =  '../test_data/order_trace_test/'+power_dir+'/cluster_info_after_removal5.fits'\n",
    "\n",
    "new_imm_after_removal = make_2D_data(index_new, x_p, y_p, nx, ny)\n",
    "order_t.make_fits(new_imm_after_removal, cluster_after_removal_fits)\n",
    "new_x, new_y, new_index, convert_map = order_t.reorganize_index(index_new, x_p, y_p, True)\n",
    "cluster_data = np.zeros((3, new_index.size))\n",
    "cluster_data[0, :] = new_index\n",
    "cluster_data[1, :] = new_x\n",
    "cluster_data[2, :] = new_y\n",
    "order_t.make_fits(cluster_data, cluster_info_after_removal_fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) load advanced cleaning results, result of step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_after_removal_fits = '../test_data_backup/order_trace_test/'+power_dir+'/cluster_after_removal5.fits'\n",
    "cluster_info_after_removal_fits =  '../test_data_backup/order_trace_test/'+power_dir+'/cluster_info_after_removal5_r.fits'\n",
    "new_imm_after_removal, hdr = fits.getdata(cluster_after_removal_fits, header=True)\n",
    "#plot_img(new_imm_after_removal, 0, np.shape(new_imm_after_removal)[0]-1)\n",
    "\n",
    "cluster_info_tmp, c_hdr = fits.getdata(cluster_info_after_removal_fits, header=True)\n",
    "new_index = cluster_info_tmp[0].astype(int)\n",
    "new_x = cluster_info_tmp[1].astype(int)\n",
    "new_y = cluster_info_tmp[2].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show result and curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y, power)\n",
    "max_index = np.amax(new_index)\n",
    "\n",
    "print(np.shape(new_coeffs))\n",
    "print(max_index)\n",
    "plot_poly_trace(new_imm_after_removal, max_index, new_coeffs, nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. clean the clusters along the top and bottom border (optional), new_x, new_y, new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_r = new_index.copy()\n",
    "x = new_x.copy()\n",
    "y = new_y.copy()\n",
    "\n",
    "index_b = order_t.clean_clusters_on_border(x, y, index_r, 0)\n",
    "print(len(index_r))\n",
    "print(len(index_b))\n",
    "\n",
    "index_t = order_t.clean_clusters_on_border(x, y, index_b, ny-1)\n",
    "new_x, new_y, new_index, convert_map = order_t.reorganize_index(index_t, x, y, True)\n",
    "print(len(index_b))\n",
    "print(len(new_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving result of step 5 to fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.zeros((3, new_index.size))\n",
    "cluster_data[0, :] = new_index\n",
    "cluster_data[1, :] = new_x\n",
    "cluster_data[2, :] = new_y\n",
    "order_t.make_fits(cluster_data, cluster_info_border_fits)\n",
    "\n",
    "imm = order_t.make_2D_data(new_index, new_x, new_y)\n",
    "order_t.make_fits(imm, cluster_border_fits)\n",
    "ind_max = np.amax(new_index)\n",
    "print('there are '+str(ind_max)+' clusters in total')\n",
    "\n",
    "yy = np.shape(imm)[0]\n",
    "plot_img(imm, 0, yy-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) load result of step 5 fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm, hdr = fits.getdata(cluster_border_fits, header=True)\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)\n",
    "\n",
    "cluster_info, c_hdr = fits.getdata(cluster_info_border_fits, header=True)\n",
    "new_index = cluster_info[0].astype(int)\n",
    "new_x = cluster_info[1].astype(int)\n",
    "new_y = cluster_info[2].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for step 6\n",
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y, power)\n",
    "max_index = np.amax(new_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for debug usage: to find the curve by giving the range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_target_curve(all_curves):\n",
    "    sel_list = list()\n",
    "    target_clusters =  [[   0.,  438., 7731., 7799.], [ 448., 1934., 7795., 7967.], [1941., 7174., 7963., 8091.]]\n",
    "\n",
    "    for i in range(1, len(all_curves)):\n",
    "        #print(all_curves[i])\n",
    "        for c in target_clusters:\n",
    "            if all_curves[i, 0] == c[0] and all_curves[i, 1] == c[1] and \\\n",
    "               all_curves[i, 2] == c[2] and all_curves[i, 3] == c[3]:\n",
    "                sel_list.append(i)\n",
    "                break\n",
    "    return sel_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merging clusters, input parameters:  index_t, x, y, imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_clusters (index, x, y, power, times=None):\n",
    "    new_index = index.copy()\n",
    "    new_x = x.copy()\n",
    "    new_y = y.copy()\n",
    "    new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y, power)\n",
    "    total = 0\n",
    "    \n",
    "    while(True):\n",
    "        all_location = new_coeffs[:, power+1:power+5]\n",
    "        total += 1\n",
    "        print('time: ', total)\n",
    "        pr = False\n",
    "                \n",
    "        n_index, n_x, n_y, n_coeffs, merge_status = order_t.one_step_merge_cluster(new_coeffs, power, \\\n",
    "                                                                new_index, new_x, new_y, print_result=pr)\n",
    "\n",
    "        log = merge_status['log']\n",
    "        print(\"  \"+log)\n",
    "            \n",
    "        new_index = n_index.copy()\n",
    "        new_x = n_x.copy()\n",
    "        new_y = n_y.copy()\n",
    "        new_coeffs = n_coeffs.copy()\n",
    "        \n",
    "        if (times is not None) and (total == times):\n",
    "            break\n",
    "        \n",
    "        if merge_status['status'] == 'nochange':\n",
    "            break\n",
    "            \n",
    "    m_x, m_y, m_index = order_t.reorganize_index(new_index, new_x, new_y)\n",
    "    m_coeffs, errors = order_t.curve_fitting_on_all_clusters(m_index, m_x, m_y, power)\n",
    "    return m_x, m_y, m_index, m_coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#m_x, m_y, m_index, m_coeffs = order_t.merge_clusters(new_index, new_x, new_y, power)\n",
    "m_x, m_y, m_index, m_coeffs = merge_clusters(new_index, new_x, new_y, power)\n",
    "new_x = m_x.copy()\n",
    "new_y = m_y.copy()\n",
    "new_index = m_index.copy()\n",
    "new_coeffs = m_coeffs.copy()\n",
    "\n",
    "max_index = np.amax(new_index)\n",
    "plot_poly_trace(imm_spec, max_index, new_coeffs, nx, ny, title='after merging cluster', size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save merge results of step 6 to fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) change filename for saving, optional\n",
    "cluster_merge_fitting = '../test_data_backup/order_trace_test/'+power_dir+'/cluster_merge_fitting_0303_sorted.fits'\n",
    "cluster_info_merge_fitting = '../test_data_backup/order_trace_test/'+power_dir+'/cluster_info_merging_fitting_0303_sorted.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store after merge fits and fits info\n",
    "imm = make_cluster_fits(new_index, new_x, new_y, nx, ny, cluster_merge_fitting)\n",
    "make_cluster_info_fits(new_index, new_x, new_y, cluster_info_merge_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coeffs = new_coeffs\n",
    "cluster_points = order_t.get_cluster_points(new_coeffs, power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) load merge result of step 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm, hdr = fits.getdata(cluster_merge_fitting, header=True)\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)\n",
    "\n",
    "cluster_info, c_hdr = fits.getdata(cluster_info_merge_fitting, header=True)\n",
    "new_index = cluster_info[0].astype(int)\n",
    "new_x = cluster_info[1].astype(int)\n",
    "new_y = cluster_info[2].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort cluster based on y position (optional)\n",
    "cluster_merge_fitting = '../test_data_backup/order_trace_test/'+power_dir+'/cluster_merge_fitting_0303_sorted.fits'\n",
    "cluster_info_merge_fitting = '../test_data_backup/order_trace_test/'+power_dir+'/cluster_info_merging_fitting_0303_sorted.fits'\n",
    "\n",
    "sorted_index = order_t.sort_cluster_in_y(cluster_coeffs, power)\n",
    "new_index_sort = np.zeros(np.size(new_index), dtype=int)\n",
    "for i in range(1, len(sorted_index)):\n",
    "    idx = np.where(new_index == sorted_index[i])[0]\n",
    "    new_index_sort[idx] = i\n",
    "new_index = new_index_sort.copy()\n",
    "\n",
    "imm = make_cluster_fits(new_index_sort, new_x, new_y, nx, ny, cluster_merge_fitting)\n",
    "make_cluster_info_fits(new_index_sort, new_x, new_y, cluster_info_merge_fitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot on result of step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y, power)\n",
    "max_index = np.amax(new_index)    \n",
    "plot_poly_trace(imm, max_index, new_coeffs, nx, ny)\n",
    "cluster_points = order_t.get_cluster_points(new_coeffs, power)\n",
    "cluster_coeffs = new_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot on specific trace \n",
    "sel_idx = 1\n",
    "\n",
    "plot_selected_clusters_on_original_img([sel_idx], new_x, new_y, new_index, new_coeffs, show_width=True, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  remove broken cluster which has big opening in the center (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x1, new_y1, new_index1 = order_t.remove_broken_cluster(new_index, new_x, new_y, new_coeffs)\n",
    "next_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index1, new_x1, new_y1, power)\n",
    "imm =  make_2D_data(new_index1, new_x1, new_y1, nx, ny)\n",
    "max_index = np.amax(new_index1)\n",
    "\n",
    "plot_poly_trace(imm, max_index, next_coeffs, nx, ny, title='after removing broken cluster', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = new_x1.copy()\n",
    "new_y = new_y1.copy()\n",
    "new_index = new_index1.copy()\n",
    "cluster_points = order_t.get_cluster_points(next_coeffs, power)\n",
    "cluster_coeffs = next_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional)  get data from pre-stored fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, hdr = fits.getdata(spectral_fits, header=True)\n",
    "yy = np.shape(data)[0]\n",
    "plot_img(data, 0, yy-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, hdr = fits.getdata(cluster_xy_fits, header=True)\n",
    "yy = np.shape(data)[0]\n",
    "plot_img(data, 0, yy-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, hdr = fits.getdata(cluster_clean_fits, header=True)\n",
    "yy = np.shape(data)[0]\n",
    "plot_img(data, 0, yy-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_border, hdr = fits.getdata(cluster_border_fits, header=True)\n",
    "yy = np.shape(imm_border)[0]\n",
    "plot_img(imm_border, 0, yy-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (optional) fitting clusters on peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_cluster_no = np.amax(new_index)\n",
    "original_coeffs = cluster_coeffs.copy()\n",
    "peak_info = order_t.curve_fitting_on_peaks(cluster_coeffs, power)\n",
    "plot_poly_trace(imm, max_cluster_no, peak_info['coeffs'], nx, ny, title=\"fitting on cluster peaks\", size=20)\n",
    "cluster_points = peak_info['peak_pixels']\n",
    "cluster_coeffs =  peak_info['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peak_info['errors'], np.mean(peak_info['errors']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) difference (RMS) between peak fitting and cluster pixel fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = order_t.rms_of_polys(original_coeffs, peak_info['coeffs'], power)\n",
    "print(rms, np.mean(rms))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) before step 9: select cluster no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cluster_no = np.amax(new_index)\n",
    "cluster_no = input(\"select clusters no. \" +\"(1-\" + str(max_cluster_no)+\") \\n\" + \n",
    "                        \"exit(E): \")\n",
    "cluster_no = int(cluster_no.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. call API to find width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_widths =  order_t.find_all_cluster_widths(new_index, new_x, new_y, cluster_coeffs,  cluster_points, power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) find width of each order, same as step 9 with print and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_widths = list()\n",
    "for n in range(1, max_cluster_no+1):\n",
    "#for n in range(cluster_no, cluster_no+1):\n",
    "    print('cluster: ', n)\n",
    "    ext_spectrum = order_t.get_spectrum_around_cluster(n, new_index, new_x, new_y, cluster_coeffs, power)\n",
    "    if ext_spectrum is not None:\n",
    "        x_s = int(nx//2)\n",
    "        x_e = int(x_s+0)\n",
    "        y_s =  ext_spectrum['min_y']\n",
    "        y_e = ext_spectrum['max_y']\n",
    "        \n",
    "        cluster_width_info = order_t.width_of_cluster_by_gaussian(n, cluster_coeffs, cluster_points, power)\n",
    "        cluster_widths.append(cluster_width_info)\n",
    "    \n",
    "        print('top width: ', cluster_width_info['avg_nwidth'], ' bottom width: ', cluster_width_info['avg_pwidth'])\n",
    "\n",
    "        if n != cluster_no:\n",
    "            continue\n",
    "        c_widths = cluster_width_info['width_info_all_x']\n",
    "        for width_at_x in c_widths:\n",
    "            xs = width_at_x['x']\n",
    "            \n",
    "            #import pdb;pdb.set_trace()    \n",
    "            info_at_x = width_at_x['width_info']\n",
    "            slope_coeffs_bound = width_at_x['slope_coeffs']\n",
    "            prev_width = info_at_x['width0']\n",
    "            next_width = info_at_x['width1']\n",
    "        \n",
    "            plot_data_at_x(ext_spectrum['data'], xs, xs, y_s, y_e, cluster_points, cluster_no=cluster_no, w1=float(prev_width), \\\n",
    "                           w2=float(next_width),  title=' width ' + prev_width + ' and '+ next_width  + ' at '+str(xs), size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) write into result from API result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_widths in cluster_widths:\n",
    "    c_no = c_widths['cluster_no']\n",
    "    width_all_x = c_widths['width_info_all_x']\n",
    "    with open(result_csv+str(c_no)+'.csv', mode='w') as result_file:\n",
    "        #import pdb;pdb.set_trace()\n",
    "        fieldname=['no', 'x', 'y', 'data','p_mid','backgd0','n_mid','backgd1','p_slope_1','p_slope_2','n_slope_1','n_slope_2','width0', 'width1' ]\n",
    "        result_writer = csv.DictWriter(result_file, fieldnames=fieldname)\n",
    "        result_writer.writeheader()\n",
    "        \n",
    "        for cluster_x in width_all_x:\n",
    "            info_x = cluster_x['width_info']\n",
    "            info_x['no']=str(cluster_no)\n",
    "            info_x['x']=str(cluster_x['x'])\n",
    "            result_writer.writerow(info_x)\n",
    "            i = 1\n",
    "            for one_slope in cluster_x['slopes_next']:\n",
    "                result_writer.writerow({'no': str(i),'y': str(one_slope[0]), 'n_slope_1': to_str(one_slope[1]), \n",
    "                                        'n_slope_2': to_str(one_slope[2]), 'data': to_str(one_slope[3])})\n",
    "                i += 1\n",
    "            i = 1   \n",
    "            for one_slope in cluster_x['slopes_prev']:\n",
    "                result_writer.writerow({'no': str(i), 'y': str(one_slope[0]), 'p_slope_1': to_str(one_slope[1]), \n",
    "                                    'p_slope_2': to_str(one_slope[2]), 'data': to_str(one_slope[3])})    \n",
    "                i += 1\n",
    "        previous_width = c_widths['avg_pwidth']\n",
    "        next_width = c_widths['avg_nwidth']\n",
    "        result_writer.writerow({'no': c_no, \"width0\": previous_width, 'width1': next_width})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. write widths result to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_poly_width_csv = '../test_data_backup/order_trace_test/'+power_dir+'/output/neid_poly_2sigma_gaussian_pixel_0303_'+str(power)+'.csv'\n",
    "print(np.shape(cluster_coeffs))\n",
    "import pdb;pdb.set_trace()\n",
    "print(np.shape(cluster_coeffs))\n",
    "order_t.write_cluster_info_to_csv(cluster_widths, cluster_coeffs, power, result_poly_width_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) test code on single column data and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_spec = spe_info['data']\n",
    "one_column_data = ori_spec[:, 2000]\n",
    "ny, nx = np.shape(ori_spec)\n",
    "x = np.arange(ny)\n",
    "y = one_column_data\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_spec = spe_info['data']\n",
    "one_column_data = ori_spec[:, 2000]\n",
    "f, A, AINV = opt_filter(one_column_data, 20)\n",
    "data= one_column_data - order_t.opt_filter(one_column_data, 20)\n",
    "x = np.arange(ny)\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(x, data)\n",
    "\n",
    "imm = np.zeros((ny, nx), dtype=np.uint8)\n",
    "mm_pos = np.where(data>0, data, 0)\n",
    "h = 0.5*np.sort(mm_pos)[mm_pos.size//2]\n",
    "print('h: ', h)\n",
    "imm[:, 2000][mm_pos>(h+1)] = 1\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(x, imm[:, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(x, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
