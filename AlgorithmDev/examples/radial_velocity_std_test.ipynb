{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models, fitting\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fit_g = fitting.LevMarLSQFitter()\n",
    "TEST_DIR = '../test_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_std_on_curve(total_data, data_set, time_list, label_list):\n",
    "    display_color = ['y', 'r', 'k', 'g', 'y', 'm', 'c'] # set the color to'w' to hide the display of any data set\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    \n",
    "    for n in range(total_data):\n",
    "        label_curve = label_list[n]\n",
    "        plt.plot(time_list, data_set[n, :], display_color[n]+'o', label=label_list[n])\n",
    "    \n",
    "    plt.legend(loc=\"upper left\", prop={'size': 12})\n",
    "    plt.xlabel('Times [Days]')\n",
    "    plt.ylabel('RV [m/s]')\n",
    "    ymax = math.ceil(np.amax(data_set))\n",
    "    ymin = math.floor(np.amin(data_set))\n",
    "    plt.ylim((ymin, ymax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fit_ccf(velocities, ccf, rv_guess, velocity_cut=100.0):\n",
    "    g_init = models.Gaussian1D(amplitude=-1e7, mean=rv_guess, stddev=5.0)\n",
    "    i_cut = (velocities >= rv_guess - velocity_cut) & (velocities <= rv_guess + velocity_cut)\n",
    "    g_x = velocities[i_cut]\n",
    "    g_y = ccf[i_cut]-np.nanmedian(ccf)\n",
    "    gaussian_fit = fit_g(g_init, g_x, g_y)\n",
    "    rv_result = gaussian_fit.mean.value\n",
    "    return gaussian_fit, rv_result, g_x, g_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harps_ccf(keystr):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    harps_file =  TEST_DIR+'rv_test/HARPStauceti_baseline/ccf/HARPS'+keystr+'_ccf_G2_A.fits'\n",
    "    harps_ccf, harps_ccf_head = fits.getdata(harps_file, header=True)\n",
    "    return harps_ccf, harps_ccf_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_ccf(keystr):\n",
    "    #other_file = TEST_DIR+'rv_test/output_cindy_fix/HARPStaucetiCindy' + keystr + '_norm_ccf_G2_A.fits'\n",
    "    other_file = TEST_DIR + 'rv_test/output_cindy_03232020/HARPStaucetiCindy' + keystr + '_norm_ccf_G2_A.fits'\n",
    "    other_ccf, other_ccf_head = fits.getdata(other_file, header=True)\n",
    "    return other_ccf, other_ccf_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Arpita output with reference output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rv_output_arpita_fits = glob.glob(TEST_DIR+'rv_test/output_arpita/*.fits')\n",
    "rv_output_arpita_fits.sort()\n",
    "total_fits = len(rv_output_arpita_fits)\n",
    "print(total_fits)\n",
    "times_array = np.zeros(total_fits, dtype=float)\n",
    "means = np.zeros((3, total_fits), dtype=float)\n",
    "\n",
    "for n in range(total_fits):\n",
    "    fits_name = rv_output_arpita_fits[n]   \n",
    "    i1 = fits_name.index('ARPITA.20')+6\n",
    "\n",
    "    harps_ccf, harps_ccf_head = get_harps_ccf(fits_name[i1:i1+24])\n",
    "    times_array[n] = harps_ccf_head['MJD-OBS']\n",
    "    \n",
    "    rv_data, rv_head = fits.getdata(fits_name, header=True)\n",
    "    other_ccf, other_ccf_head = get_other_ccf(fits_name[i1:i1+24])\n",
    "\n",
    "    s = np.shape(rv_data)\n",
    "    v_size = s[0]\n",
    "    vel_sum = rv_data[v_size-1, :]\n",
    "    vel_loop = rv_data[v_size-2, :]\n",
    "    rv_fit, rv_result, g_x, g_y = fit_ccf(vel_loop, vel_sum, vel_loop[int(s[1]/2)])\n",
    " \n",
    "    harps_mean = harps_ccf_head['HIERARCH ESO DRS CCF RVC']\n",
    "    other_mean = other_ccf_head['CCF-RVC']\n",
    "    \n",
    "    means[0][n] = harps_mean\n",
    "    means[1][n] = rv_result\n",
    "    means[2][n] = other_mean\n",
    "\n",
    "\n",
    "min_time = np.amin(times_array)\n",
    "times_0 = times_array - min_time\n",
    "\n",
    "mean_harps = np.mean(means[0, :])\n",
    "mean_rv = np.mean(means[1, :])\n",
    "mean_other = np.mean(means[2, :])\n",
    "\n",
    "#print('mean: ', mean_harps, mean_rv, mean_other)\n",
    "\n",
    "offset_rv = np.zeros((3, times_array.size), dtype=float)\n",
    "offset_rv[0, :] = (means[0, :] - mean_harps) * 1000.0\n",
    "offset_rv[1, :] = (means[1, :] - mean_rv) * 1000.0\n",
    "offset_rv[2, :] = (means[2, :] - mean_other) * 1000.0\n",
    "\n",
    "std_label = list()\n",
    "std_label.append('HARPS Sigma =' + str(np.std(offset_rv[0, :])) + ' m/s')\n",
    "std_label.append('Arpita Sigma =' + str(np.std(offset_rv[1, :])) + ' m/s')\n",
    "std_label.append('Cindy Sigma =' + str(np.std(offset_rv[2, :])) + ' m/s')\n",
    "\n",
    "#import pdb; pdb.set_trace()\n",
    "plot_std_on_curve(3, offset_rv, times_0, std_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
