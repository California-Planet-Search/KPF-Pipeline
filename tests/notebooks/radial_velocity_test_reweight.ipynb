{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import warnings\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.time import Time\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import configparser\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from astropy import constants as const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.radial_velocity.src.alg import RadialVelocityAlg\n",
    "from modules.radial_velocity.src.alg_rv_init import RadialVelocityAlgInit\n",
    "load_dotenv()\n",
    "TEST_DIR = os.getenv('KPFPIPE_TEST_DATA') \n",
    "print('TEST_DIR:', TEST_DIR)\n",
    "FIT_G = fitting.LevMarLSQFitter()\n",
    "LIGHT_SPEED = 299792.458   # light speed in km/s\n",
    "class DotDict(dict):\n",
    "    pass\n",
    "MODULE_DIR = '../../modules/radial_velocity/'\n",
    "reweight_method = 'ccf_max'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MJD_TO_JD = 2400000.5\n",
    "class RadialVelocityStats:\n",
    "    \"\"\" This module defines class ' RadialVelocityStats' and methods to do statistic analysis on radial velocity\n",
    "    results. (this is currently for radial velocity development and testing only).\n",
    "\n",
    "    Attributes:\n",
    "         rv_result_set (list): A container storing radial velocity result from fits of level 1 data.\n",
    "         total_set (int): Total elements in `rv_result_set`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_rv_results: list = None):\n",
    "        self.rv_result_set = list() if obs_rv_results is None else obs_rv_results.copy()\n",
    "        self.total_set = 0 if obs_rv_results is None else len(obs_rv_results)\n",
    "\n",
    "    def get_collection(self):\n",
    "        return self.rv_result_set, self.total_set\n",
    "\n",
    "    def add_data(self, ccf_rv: float, obj_jd: float):\n",
    "        self.rv_result_set.append({'jd': obj_jd, 'mean_rv': ccf_rv})\n",
    "        self.total_set = len(self.rv_result_set)\n",
    "        return self.rv_result_set, self.total_set\n",
    "\n",
    "    def analyze_multiple_ccfs(self, ref_date=None):\n",
    "        \"\"\" Statistic analysis on radial velocity numbers of multiple observation resulted by `RadialVelocityAlg`.\n",
    "\n",
    "        Args:\n",
    "            ref_date (str, optional): Reference time in the form Julian date format.  Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            dict: Analysis data.\n",
    "\n",
    "        \"\"\"\n",
    "        obs_rvs, total_obs = self.get_collection()\n",
    "        jd_list = np.array([obs_rv['jd'] for obs_rv in obs_rvs])\n",
    "        if ref_date is None:\n",
    "            ref_jd = self.get_start_day(jd_list)\n",
    "        else:\n",
    "            ref_jd = Time(ref_date, format='isot', scale='utc').jd\n",
    "        rv_stats = dict()\n",
    "        rv_stats['start_jd'] = ref_jd\n",
    "        rv_stats['hour'] = (jd_list-ref_jd) * 24.0\n",
    "        rv_stats['day'] = (jd_list-ref_jd)\n",
    "        rv_stats['values'] = np.array([obs_rv['mean_rv'] for obs_rv in obs_rvs])\n",
    "        rv_stats['mean'] = np.mean(rv_stats['values'])\n",
    "        rv_stats['sigma'] = np.std(rv_stats['values'] - rv_stats['mean'])\n",
    "\n",
    "        return rv_stats\n",
    "\n",
    "    @staticmethod\n",
    "    def get_start_day(jd_list: np.ndarray):\n",
    "        min_jd = np.amin(jd_list)\n",
    "        day_part = math.floor(min_jd - MJD_TO_JD)\n",
    "        return MJD_TO_JD+day_part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gaussian_on_curve(g_curve, curve_x, curve_y, order=None, title=None, ref_curve=None, ref_gaussian=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    label_curve = \"rv on order \" + str(order) if order is not None else 'after reweighting'\n",
    "    plt.plot(curve_x, curve_y, 'ko', label=label_curve)\n",
    "    if ref_curve is not None:\n",
    "        plt.plot(curve_x, ref_curve, 'mo', label=\"before reweighting\"  )\n",
    "        plt.plot(curve_x, ref_gaussian(curve_x), label='Gaussian w/ mean:'+str(\"{0:.6f}\".format(ref_gaussian.mean.value)))\n",
    "    plt.plot(curve_x, g_curve(curve_x), label='Gaussian w/ mean:'+str(\"{0:.6f}\".format(g_curve.mean.value)))\n",
    "                                                      \n",
    "    plt.legend(loc=\"lower right\", prop={'size': 12})\n",
    "    plt.title(title) if title is not None else None\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "dev = 'dev'\n",
    "def plot_velocity_time(rv_info, title, label, color, time_unit='hrs', savefig=None):\n",
    "    k1 = list(rv_info.keys())[0]\n",
    "    \n",
    "    total_rv = np.size(rv_info[k1]['values'])\n",
    "\n",
    "    if time_unit == 'hrs':\n",
    "        rv_delta_time = rv_info[k1]['hour'] \n",
    "    else:\n",
    "        rv_delta_time = rv_info[k1]['day']\n",
    "        \n",
    "    plt.figure(figsize=(10,12))     \n",
    "    s = 100\n",
    "    ymax = -10000\n",
    "    ymin = 10000\n",
    "    for k in rv_info.keys():\n",
    "        rv_offset = (rv_info[k]['values'] - rv_info[k]['mean']) * 1000.0\n",
    "        ymax = max(np.amax(rv_offset), ymax)\n",
    "        ymin = min(np.amin(rv_offset), ymin)\n",
    "        rv_sigma = rv_info[k]['sigma']*1000.0\n",
    "        plt.scatter(rv_delta_time, rv_offset, s, c=color[k], edgecolors='b', \n",
    "                    label=label[k] + r' $\\sigma = $'+ \"{:0.6f}\".format(rv_sigma)+' m/s')\n",
    "        \n",
    "\n",
    "    plt.legend(loc=\"upper right\", prop={'size':12})\n",
    "    plt.xlabel('Times ['+time_unit+']')\n",
    "    plt.ylabel('RV [m/s]')\n",
    "\n",
    "    ymax = math.ceil(ymax)+1\n",
    "    ymin = math.floor(ymin)-1\n",
    "    xmin = math.ceil(np.amin(rv_delta_time))\n",
    "    xmax = math.floor(np.amax(rv_delta_time))\n",
    "    if time_unit == 'hrs':\n",
    "        plt.xlim((xmin-1, xmax+1))\n",
    "    else:\n",
    "        plt.xlim((xmin-20, xmax+20))\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    \n",
    "    if savefig is not None:\n",
    "        plt.savefig(savefig)\n",
    "    plt.show()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ccf(result_ccf, total_order, velocity_cut=100.0):\n",
    "    rv_guess = -0.5\n",
    "    row_for_analysis = np.arange(1, total_order, dtype=int)\n",
    "    result_ccf[total_order + 2, :] = np.nansum(result_ccf[row_for_analysis, :], axis=0)\n",
    "    g_init = models.Gaussian1D(amplitude=-1e7, mean=rv_guess, stddev=5.0)\n",
    "    velocities = result_ccf[total_order + 1, :]\n",
    "    ccf = result_ccf[total_order + 2, :]\n",
    "    i_cut = (velocities >= rv_guess - velocity_cut) & (velocities <= rv_guess + velocity_cut)\n",
    "    g_x = velocities[i_cut]\n",
    "    g_y = ccf[i_cut] - np.nanmedian(ccf)\n",
    "    gaussian_fit = FIT_G(g_init, g_x, g_y)\n",
    "    return gaussian_fit, gaussian_fit.mean.value, g_x, g_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot level 1 flux vs. orders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot L1 results of selected order\n",
    "def plot_level1_data(lev1_data, selected_order, check_order=False, title=None):\n",
    "    colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'coral', 'purple', 'orange']\n",
    "    n_colors = len(colors)\n",
    "    plt.figure(figsize=(18,6))   \n",
    "    point_per_order = 1\n",
    "    s_point = 0\n",
    "    c_idx = 0\n",
    "    for ord in selected_order:\n",
    "        v_order = lev1_data[ord, :]\n",
    "        max_v = np.nanpercentile(v_order, 95)\n",
    "        p_list = np.where(v_order <= max_v)[0]\n",
    "        # n_points = np.size(v_order)\n",
    "        # p_list = np.arange(0, n_points, point_per_order, dtype=int)\n",
    "        y_data = v_order[p_list]\n",
    "        x_data = np.arange(s_point, s_point+np.size(y_data), dtype=int)\n",
    "        nan_idx = np.where(np.isnan(y_data))[0]\n",
    "        if np.size(nan_idx) > 0:\n",
    "            y_data[nan_idx] = 0.0\n",
    "        neg_idx = np.where(y_data < 0)[0]\n",
    "        if np.size(neg_idx) > 0:\n",
    "            y_data[neg_idx] = 0.0\n",
    "        if check_order:\n",
    "            import pdb;pdb.set_trace()\n",
    "        plt.plot(x_data, y_data, c = colors[c_idx%n_colors])\n",
    "        s_point += np.size(x_data) - 1  \n",
    "        c_idx += 1\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spectrum_set = TEST_DIR + '/NEIDdata/HD127334/L2/neidL2_*.fits'\n",
    "ccf_idx = -1\n",
    "\n",
    "s_idx = 0\n",
    "e_idx = 116\n",
    "order_diff = 0\n",
    "Files = sorted(glob.glob(spectrum_set))\n",
    "\n",
    "for f_idx in range(len(Files)):\n",
    "    f = Files[f_idx]\n",
    "    hdulist = fits.open(f)\n",
    "    lev1_data = hdulist[1].data\n",
    "    max_v = np.max(lev1_data)\n",
    "    max_pos = np.where(lev1_data == max_v)\n",
    "    print('file: ', f, 'max: ', max_v, 'max_loc: ', max_pos)\n",
    "    # import pdb;pdb.set_trace()\n",
    "    plot_level1_data(lev1_data, np.arange(s_idx, e_idx+1, dtype=int), title='level 1 for '+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RV computation on NEID L1 data and results from Optimal Extraction module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# original NEID level 2 data\n",
    "neid_L1_L2_dir = TEST_DIR + '/NEIDdata/HD127334/L2/neidL2'\n",
    "neid_L2_files =  sorted(glob.glob(neid_L1_L2_dir + '*.fits'))\n",
    "\n",
    "print('\\n'.join(neid_L2_files))\n",
    "\n",
    "lev2_result_dir = '../../test_results/neid_hd127334/'\n",
    "lev2_result_files = sorted(glob.glob(lev2_result_dir + 'neidL1*_L2.fits'))\n",
    "\n",
    "outfolder = MODULE_DIR+'results/NEID_HD127334/'\n",
    "\n",
    "s_order=0\n",
    "e_order=116\n",
    "order_diff = 0\n",
    "s_x_pos = 600\n",
    "\n",
    "# import pdb;pdb.set_trace()\n",
    "print('\\n'.join(lev2_result_files))\n",
    "total_file = len(lev2_result_files)\n",
    "\n",
    "\"\"\"\n",
    "config_file = MODULE_DIR + 'configs/default_recipe_neid_hd127334.cfg'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "logger = start_logger(\"OrderTraceAlg\", config_file)\n",
    "\n",
    "rv_init = RadialVelocityAlgInit(config, logger)\n",
    "init_result = rv_init.start(print_debug='')\n",
    "\"\"\"\n",
    "rv_dev_info = RadialVelocityStats()\n",
    "rv_dev_reweight_info = RadialVelocityStats()\n",
    "rv_lev2_info = RadialVelocityStats()\n",
    "rv_lev2_reweight_info = RadialVelocityStats()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pick the template and do reweighting on NEID/developed level2 result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "allcpp = []\n",
    "\n",
    "for f in range(len(lev2_result_files)):\n",
    "    hdul = fits.open(lev2_result_files[f])\n",
    "    ccf = pd.DataFrame(hdul[12].data).values           # a Table HDU\n",
    "    ccf_max = np.nanmax([np.nanpercentile(ccf[od, :], 95) for od in range(s_order, e_order+1)])\n",
    "    allcpp.append(ccf_max)\n",
    "    # plt.figure(figsize=(12,6))\n",
    "    # plt.plot(np.transpose(ccf[s_order:e_order+1, :]))\n",
    "    # plt.title(lev2_result_files[f])\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "index = np.where(allcpp == np.max(allcpp))\n",
    "index = np.squeeze(index[0])\n",
    "print(index, lev2_result_files[index])\n",
    "template_file_hdulist = fits.open(lev2_result_files[index])\n",
    "template_ccf = pd.DataFrame(template_file_hdulist[12].data).values\n",
    "ratio_file = MODULE_DIR + 'results/NEID_HD127334/hd127334_ratio.csv'\n",
    "rw_ratio_df = RadialVelocityAlg.make_reweighting_ratio_table(template_ccf, s_order, e_order, reweight_method,\n",
    "                                                             max_ratio=1.0, output_csv=ratio_file)\n",
    "# print(rw_ratio_df.values)\n",
    "\n",
    "allcpp_lev2 = []\n",
    "for f in range(len(neid_L2_files)):\n",
    "    hdul = fits.open(neid_L2_files[f])\n",
    "    ccf = hdul[12].data                               # an Image HDU\n",
    "    allcpp_lev2.append(np.max(ccf[s_order:e_order+1, :]))\n",
    "    # plt.figure(figsize=(12,6))\n",
    "    # plt.plot(np.transpose(ccf[s_order:e_order+1, :]))\n",
    "    # plt.title(neid_L2_files[f])\n",
    "    # plt.show()\n",
    "             \n",
    "index = np.where(allcpp_lev2 == np.max(allcpp_lev2))   \n",
    "index = np.squeeze(index[0])\n",
    "print(index, neid_L2_files[index])\n",
    "template_neid_lev2_hdulist = fits.open(neid_L2_files[index])\n",
    "template_neid_ccf = template_neid_lev2_hdulist[12].data\n",
    "rw_ratio_lev2_df = RadialVelocityAlg.make_reweighting_ratio_table(template_neid_ccf, s_order, e_order, \n",
    "                                                                  reweight_method, max_ratio=1.0)\n",
    "# print(rw_ratio_lev2_df.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reweight on calculated ccf and NEID ccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_ccf = []\n",
    "total_order = e_order-s_order+1\n",
    "rv_total = np.zeros((len(lev2_result_files), 164))\n",
    "after_reweighting_total = np.zeros((len(lev2_result_files), 164))\n",
    "for f in range(len(lev2_result_files)):\n",
    "    \n",
    "    # reweight NEID level 2 ccf\n",
    "    print(neid_L2_files[f])\n",
    "    neid_L2_file_hdulist = fits.open(neid_L2_files[f])\n",
    "    L1_time = neid_L2_file_hdulist[12].header['CCFJDSUM']\n",
    "    rv_guess = neid_L2_file_hdulist[0].header['QRV']\n",
    "    ny, nx = np.shape(neid_L2_file_hdulist[12].data)\n",
    "    \n",
    "    \n",
    "    # add info from L2 data\n",
    "    simplerv = neid_L2_file_hdulist[12].header['CCFRVSUM']\n",
    "    rv_lev2_info.add_data(simplerv, L1_time)\n",
    "    \n",
    "    neid_L2_ccf = np.zeros((total_order+3, nx))\n",
    "    neid_L2_ccf[0:ny, :] = neid_L2_file_hdulist[12].data\n",
    "    start_rv = neid_L2_file_hdulist[12].header['CCFSTART']\n",
    "    step_size = neid_L2_file_hdulist[12].header['CCFSTEP']\n",
    "    total_step = nx;\n",
    "    neid_L2_ccf[total_order+1, :] = np.arange(-total_step/2, total_step/2, dtype=int)*step_size + 0.0\n",
    "    \n",
    "    reweighted_lev2_ccf = RadialVelocityAlg.reweight_ccf(neid_L2_ccf, total_order, rw_ratio_lev2_df.values, \n",
    "                                                    reweight_method, do_analysis=True)\n",
    "\n",
    "    # import pdb;pdb.set_trace()\n",
    "    # rw_lev2_ccf_fit, rw_lev2_ccf_mean, n_x, n_y = RadialVelocityAlg.fit_ccf(reweighted_lev2_ccf[total_order+2, :],\n",
    "    #                                                                        rv_guess, \n",
    "    #                                                                        neid_L2_ccf[total_order+1, :])\n",
    "    reweighted_lev2_ccf[total_order+1, :] = neid_L2_ccf[total_order+1, :]\n",
    "    rw_lev2_ccf_fit, rw_lev2_ccf_mean, n_x, n_y = fit_ccf(reweighted_lev2_ccf, total_order)\n",
    "    rv_lev2_reweight_info.add_data(rw_lev2_ccf_mean, L1_time) \n",
    "    \n",
    "    # reweight calculated L2 data\n",
    "    print(lev2_result_files[f])\n",
    "    file_hdulist = fits.open(lev2_result_files[f])\n",
    "    ccf_data = pd.DataFrame(file_hdulist[12].data).values\n",
    "    \n",
    "    rv_ccf_fit, rv_ccf_mean, n_x, n_y = fit_ccf(ccf_data, total_order)\n",
    "    \n",
    "    # add info from calculated L2 data\n",
    "    rv_dev_info.add_data(rv_ccf_mean, L1_time)\n",
    "    rv_total[f, :] = ccf_data[total_order+2, :]\n",
    "\n",
    "    # add info from weighted L2 data\n",
    "    reweighted_ccf = RadialVelocityAlg.reweight_ccf(ccf_data, total_order, rw_ratio_df.values, \n",
    "                                        reweight_method, do_analysis=True)\n",
    "    reweighted_ccf[total_order+1, :] = ccf_data[total_order+1, :]\n",
    "    after_reweighting_total[f, :] = reweighted_ccf[total_order+2, :]\n",
    "    #ccf_fit, ccf_mean, n_x, n_y = RadialVelocityAlg.fit_ccf(reweighted_ccf[total_order+2, :], rv_guess, \n",
    "    #                                                        ccf_data[total_order+1, :])\n",
    "    ccf_fit, ccf_mean, n_x, n_y = fit_ccf(reweighted_ccf, total_order)\n",
    "    rv_dev_reweight_info.add_data(ccf_mean, L1_time)\n",
    "    \n",
    "    # before_ccf_fit, before_mean, before_x, before_y = RadialVelocityAlg.fit_ccf(ccf_data[total_order+2, :], rv_guess, \n",
    "    #                                                                            ccf_data[total_order+1, :])\n",
    "    before_ccf_fit, before_mean, before_x, before_y = fit_ccf(ccf_data, total_order)\n",
    "    \n",
    "    plot_gaussian_on_curve(ccf_fit, n_x, n_y, ref_curve=before_y, ref_gaussian=before_ccf_fit)\n",
    "    \n",
    "    # plt.figure(figsize=(18,6))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.plot(np.transpose(rv_total))\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.plot(np.transpose(after_reweighting_total))\n",
    "    # plt.show()   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RV vs. time from the results of above RV computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_dev_stats = rv_dev_info.analyze_multiple_ccfs()\n",
    "rv_dev_reweight_stats = rv_dev_reweight_info.analyze_multiple_ccfs()\n",
    "rv_lev2_stats = rv_lev2_info.analyze_multiple_ccfs()\n",
    "rv_lev2_reweight_stats = rv_lev2_reweight_info.analyze_multiple_ccfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rv_dev_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rv_dev_reweight_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rv_lev2_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rv_lev2_reweight_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing weighted and un-weighted result\n",
    "rv_stats = {'dev': rv_dev_stats, 'dev_weighted': rv_dev_reweight_stats, \n",
    "            'lev2': rv_lev2_stats,\n",
    "            'lev2_weighted': rv_lev2_reweight_stats}\n",
    "\n",
    "plot_velocity_time(rv_stats, \"weighting analysis\", {'dev': \"Cindy before\", \n",
    "                                                    'dev_weighted': \"Cindy: after\",\n",
    "                                                    'lev2': 'NEID: before',\n",
    "                                                    'lev2_weighted': \"NEID: after\"}, \n",
    "                   {'dev': 'cyan', 'dev_weighted': 'blue', 'lev2': 'magenta',\n",
    "                    'lev2_weighted': 'red'},\n",
    "                    time_unit='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_stats = {'dev': rv_dev_stats, 'dev_weighted': rv_dev_reweight_stats}\n",
    "\n",
    "plot_velocity_time(rv_stats, \"weighting analysis\", {'dev': \"Cindy before\", \n",
    "                                                    'dev_weighted': \"Cindy: after\"}, \n",
    "                   {'dev': 'cyan', 'dev_weighted': 'blue'},\n",
    "                    time_unit='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing weighted and un-weighted result\n",
    "rv_stats = {'lev2': rv_lev2_stats,\n",
    "            'lev2_weighted': rv_lev2_reweight_stats}\n",
    "\n",
    "plot_velocity_time(rv_stats, \"weighting analysis\", {'lev2': 'NEID: before',\n",
    "                                                    'lev2_weighted': \"NEID: after\"}, \n",
    "                   {'lev2': 'magenta',\n",
    "                    'lev2_weighted': 'red'},\n",
    "                    time_unit='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
