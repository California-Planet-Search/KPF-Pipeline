{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import math\n",
    "from scipy import ndimage, misc\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "import csv\n",
    "import pickle\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import colors\n",
    "import configparser\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "import logging\n",
    "%matplotlib inline\n",
    "power = 3\n",
    "power_dir = \"output_neid_order_trace\"\n",
    "# power_dir = \"output_paras_order_trace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.order_trace.src.alg import OrderTraceAlg\n",
    "TEST_DIR = '/Users/cwang/documents/KPF/KPF-Pipeline/AlgorithmDev_07122020/test_data_04032020/'\n",
    "load_dotenv()\n",
    "KPF_TESTDATA = os.getenv('KPFPIPE_TEST_DATA') + '/'\n",
    "print(KPF_TESTDATA)\n",
    "MODULE_DIR = '../../modules/order_trace/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.regression import test_order_trace\n",
    "# add __init__.py tentatively for testing the following functions.\n",
    "test_order_trace.test_init_exceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "test_order_trace.test_locate_clusters_paras()\n",
    "test_order_trace.test_form_clusters_paras()\n",
    "test_order_trace.test_advanced_cluster_cleaning_paras()\n",
    "test_order_trace.test_clean_clusters_on_borders_paras()\n",
    "test_order_trace.test_merge_clusters_and_clean_paras()\n",
    "test_order_trace.test_find_widths_paras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test_order_trace.test_extract_order_trace_paras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: spectral fits is from dropbox KPF-Pipeline-TestData/order_trace_test\n",
    "spectral_fits=  KPF_TESTDATA + 'polygon_clipping_test/paras_data/paras.flatA.fits'\n",
    "output_dir = MODULE_DIR + 'results/result_data'\n",
    "output_img_dir = MODULE_DIR + 'results/result_img'\n",
    "\n",
    "# output\n",
    "cluster_info_xy_csv = output_dir +'/cluster_xy_info_paras.csv'\n",
    "\n",
    "cluster_clean_fits = output_img_dir+'/cluster_form_paras.fits'\n",
    "cluster_info_clean_csv = output_dir + '/cluster_form_info_paras.csv'\n",
    "\n",
    "cluster_after_removal_fits = output_img_dir + '/cluster_clean_paras.fits'\n",
    "cluster_info_after_removal_csv = output_dir + '/cluster_clean_info_paras.csv'\n",
    "\n",
    "cluster_border_fits = output_img_dir +'/cluster_clean_border_paras.fits'\n",
    "cluster_info_border_csv = output_dir + '/cluster_clean_border_info_paras.csv'\n",
    "\n",
    "cluster_merge_fitting = output_img_dir+'/cluster_merge_paras.fits'\n",
    "cluster_info_merge_fitting_csv = output_dir+'/cluster_merge_info_paras.csv'\n",
    "\n",
    "result_csv = output_dir + '/cluster_curve_paras.csv'\n",
    "result_poly_width_csv =  TEST_DIR + 'order_trace_test/'+power_dir+'/output/paras_result_poly_3sigma_gaussian_pixel_'+str(power)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: spectral fits is from dropbox KPF-Pipeline-TestData/NEIData/FLAT\n",
    "spectral_fits= KPF_TESTDATA + '/NEIDdata/FLAT/stacked_2fiber_flat.fits'\n",
    "output_dir = MODULE_DIR + 'results/result_data'\n",
    "output_img_dir = MODULE_DIR + 'results/result_img'\n",
    "\n",
    "# output\n",
    "cluster_info_xy_csv = output_dir +'/cluster_xy_info_neid.csv'\n",
    "\n",
    "cluster_clean_fits = output_img_dir+'/cluster_form_neid.fits'\n",
    "cluster_info_clean_csv = output_dir + '/cluster_form_info_neid.csv'\n",
    "\n",
    "cluster_after_removal_fits = output_img_dir + '/cluster_clean_neid.fits'\n",
    "cluster_info_after_removal_csv = output_dir + '/cluster_clean_info_neid.csv'\n",
    "\n",
    "cluster_border_fits = output_img_dir +'/cluster_clean_border_neid.fits'\n",
    "cluster_info_border_fits = output_dir + '/cluster_clean_border_info_neid.csv'\n",
    "\n",
    "cluster_merge_fitting = output_img_dir+'/cluster_merge_neid.fits'\n",
    "cluster_info_merge_fitting_csv = output_dir+'/cluster_merge_info_neid.csv'\n",
    "\n",
    "result_csv = output_dir + '/cluster_curve_neid.csv'\n",
    "result_poly_width_csv =  TEST_DIR + 'order_trace_test/'+power_dir+'/output/neid_result_poly_3sigma_gaussian_pixel_'+str(power)+'.csv'\n",
    "#result_poly_width_csv =  output_dir + 'order_trace_test/'+ power_dir+'/output/neid_result_poly_3sigma_gaussian_pixel_'+str(power)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of start_logger from logger.py\n",
    "def get_level(lvl:str) -> int:\n",
    "    if lvl == 'debug': return logging.DEBUG\n",
    "    elif lvl == 'info': return logging.INFO\n",
    "    elif lvl == 'warning': return logging.WARNING\n",
    "    elif lvl == 'error': return logging.ERROR\n",
    "    elif lvl == 'critical': return logging.CRITICAL\n",
    "    else: return logging.NOTSET\n",
    "\n",
    "def start_logger(logger_name: str, config: str):\n",
    "    if config is None: \n",
    "        # a config file is not provided, so don't start logger\n",
    "        print('[{}] missing log configuration...not starting a new logger'.format(\n",
    "            logger_name))\n",
    "        return None\n",
    "    config_obj = configparser.ConfigParser()\n",
    "    res = config_obj.read(config)\n",
    "    if res == []:\n",
    "        return None\n",
    "\n",
    "    log_cfg = config_obj['LOGGER']\n",
    "\n",
    "    log_start = log_cfg.get('start_log', False)\n",
    "    log_path = log_cfg.get('log_path', 'log')\n",
    "    log_lvl = log_cfg.get('log_level', logging.WARNING)\n",
    "    log_verbose = log_cfg.getboolean('log_verbose', True)\n",
    "    # logger.setLevel(get_level(log_lvl))\n",
    "        \n",
    "    # if log_start:\n",
    "    #     # setup a log format\n",
    "    #     formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    #     # setup a log file\n",
    "    #     f_handle = logging.FileHandler(log_path, mode='w') # logging to file\n",
    "    #     f_handle.setLevel(get_level(log_lvl))\n",
    "    #     f_handle.setFormatter(formatter)\n",
    "    #     logger.addHandler(f_handle)\n",
    "\n",
    "    #     if log_verbose: \n",
    "    #         # also print to terminal \n",
    "    #         s_handle = logging.StreamHandler()\n",
    "    #         s_handle.setLevel(get_level(log_lvl))\n",
    "    #         s_handle.setFormatter(formatter)\n",
    "    #         logger.addHandler(s_handle)\n",
    "    # return logger\n",
    "\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(get_level(log_lvl))\n",
    "    logger.propagate = False\n",
    "\n",
    "    formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    s_handle = logging.StreamHandler()\n",
    "    s_handle.setLevel(get_level(log_lvl))\n",
    "    s_handle.setFormatter(formatter)\n",
    "    logger.addHandler(s_handle)\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imshow(img):\n",
    "    if (np.amax(img) == 1) and (np.amin(img) == 0):\n",
    "        print('is bw image')\n",
    "        im = plt.imshow(img * -1, cmap='gray')\n",
    "    else:    \n",
    "        im = plt.imshow(img, cmap='gray', norm=LogNorm())\n",
    "    return im    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image from fits by setting area xmin, xmax, ymin, ymax\n",
    "def plot_img(img, ymin, ymax, p_w=20, p_h=20, xmin=None, xmax=None, title=\"\", aspect=None):\n",
    "    #if is_bw is True:\n",
    "    #    img = convert_to_bw(img)\n",
    "    plt.figure(figsize=(p_w, p_h), frameon=False)\n",
    "    plt.subplot(1, 1, 1)\n",
    "    if xmin is None:\n",
    "        xmin = 0\n",
    "    if xmax is None:\n",
    "        h, w = np.shape(img)\n",
    "        xmax = w-1\n",
    "    s_img = img[:, :]\n",
    "    im = plot_imshow(s_img)\n",
    "\n",
    "    #im = plt.imshow(s_img, cmap='gray')\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.title(title)\n",
    "    if aspect is not None:\n",
    "        plt.axes().set_aspect(aspect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fits(data, output_fits):\n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    hdu.writeto(output_fits, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image data in 2D based on selected clusters\n",
    "def make_2D_data(index, x, y, nx, ny, selected_clusters=None):\n",
    "    imm = np.zeros((ny, nx), dtype=np.uint8)\n",
    "    \n",
    "    if selected_clusters is None:\n",
    "        selected_clusters = np.arange(1, np.amax(index)+1, dtype=int)\n",
    "\n",
    "    for idx in selected_clusters:\n",
    "        crt_idx = np.where(index == idx)[0]\n",
    "        imm[y[crt_idx], x[crt_idx]] = 1\n",
    "        \n",
    "    return imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fits on 2D of all clusters\n",
    "def make_cluster_fits(index, x, y, nx, ny, fits_path=None):\n",
    "    imm = make_2D_data(index, x, y,  nx, ny)\n",
    "    if fits_path is not None:\n",
    "        make_fits(imm, fits_path)\n",
    "        ind_max = np.amax(index)\n",
    "        print('there are '+str(ind_max)+' clusters in total in fits, '+fits_path)\n",
    "    return imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fits on cluster info (index, x, y)\n",
    "def make_cluster_info_fits(file_path, nx, ny, x_idx, y_idx, index=None):\n",
    "    size = x_idx.size\n",
    "    cluster_data = np.zeros((2, size), dtype=int) if index is None else np.zeros((3, size), dtype=int)\n",
    "    cluster_data[0, :] = x_idx\n",
    "    cluster_data[1, :] = y_idx\n",
    "    if index is not None:\n",
    "        cluster_data[2, :] = index\n",
    "    hdu = fits.PrimaryHDU(cluster_data)\n",
    "    hdu.header['indexmax'] = np.amax(index) if index is not None else 0\n",
    "    hdu.header['width'] = nx\n",
    "    hdu.header['height'] = ny\n",
    "    hdu.writeto(file_path, overwrite=True)\n",
    "    \n",
    "def get_cluster_info_fits(file_path: str):\n",
    "    cluster_info, cluster_info_head = fits.getdata(file_path, header=True)\n",
    "    x = cluster_info[0, :].astype(int)\n",
    "    y = cluster_info[1, :].astype(int)\n",
    "    index_list = None\n",
    "    if cluster_info_head['indexmax'] != 0:\n",
    "        index_list = cluster_info[2, :].astype(int)\n",
    "\n",
    "    return x, y, index_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fits on cluster info (index, x, y)\n",
    "def make_cluster_info_csv(file_path, nx, ny, x_idx, y_idx, index=None):\n",
    "    size = x_idx.size\n",
    "    cluster_data = np.zeros((size, 2), dtype=int) if index is None else np.zeros((size, 3), dtype=int)\n",
    "    cluster_data[:, 0] = x_idx\n",
    "    cluster_data[:, 1] = y_idx\n",
    "    if index is not None:\n",
    "        cluster_data[:, 2] = index\n",
    "    df = pd.DataFrame(cluster_data)\n",
    "    df.to_csv(file_path, header=False, index=False)     \n",
    "    \n",
    "def get_cluster_info_csv(file_path: str):\n",
    "    x = None\n",
    "    y = None\n",
    "    index = None\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path, header=None, index_col=None)\n",
    "        row, col = np.shape(df.values)\n",
    "        x = df.values[:, 0].astype(int) if col >= 1 else None\n",
    "        y = df.values[:, 1].astype(int) if col >= 2 else None\n",
    "        index = df.values[:, 2].astype(int) if col >= 3 else None\n",
    "    return x, y, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot polynomial fitting curve on top of given 2D image\n",
    "# the cluster orders is settable by order_set\n",
    "def plot_poly_trace(imm, total_order, coeffs_orders, max_x, max_y, size=20, order_set=None, \\\n",
    "                    title=None, background=False, widths=None, aspect=None, xmin=None, xmax=None, ymin=None, ymax=None):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    im = plot_imshow(imm)\n",
    "    #im = plt.imshow(imm, cmap='gray', norm=LogNorm())\n",
    "    \n",
    "    if order_set is None:\n",
    "        orders = list(range(1, total_order+1))\n",
    "    else:\n",
    "        orders = order_set\n",
    "        \n",
    "    x_dist = max_x//20    \n",
    "                   \n",
    "    for o_idx, order in enumerate(orders):\n",
    "        if (background is not False):\n",
    "            x_val = np.arange(0, max_x)\n",
    "            # y value on x range\n",
    "            y_val = np.polyval(coeffs_orders[order, 0:power+1], x_val)\n",
    "            plt.plot(x_val, y_val, 'b--')\n",
    "        #print(\"x range: \", coeffs_orders[order, power+1], coeffs_orders[order, power+2])    \n",
    "        # x range\n",
    "        x_val = np.arange(coeffs_orders[order, power+1], coeffs_orders[order, power+2]+1)\n",
    "        # y value on x range\n",
    "        y_val = np.polyval(coeffs_orders[order, 0:power+1], x_val)\n",
    "        plt.plot(x_val, y_val, 'r--')\n",
    "        \n",
    "        if widths is not None:\n",
    "            y_val_bottom = y_val-widths[o_idx][0]\n",
    "            plt.plot(x_val, y_val_bottom, 'g--')\n",
    "            y_val_top = y_val+widths[o_idx][1]\n",
    "            plt.plot(x_val, y_val_top, 'g--')\n",
    "        \n",
    "        # show number of cluster\n",
    "        s = ((order%15)+1)*x_dist\n",
    "        if s >= x_val.size:\n",
    "            dem = int((coeffs_orders[order, power+2] - coeffs_orders[order, power+1])//5)\n",
    "            s = dem*((order%4)+1)\n",
    "            #s = x_val.size//2\n",
    "        plt.text(x_val[s], y_val[s], str(order), fontsize=12, color='b', fontweight='bold', horizontalalignment='center', verticalalignment='center')\n",
    "        \n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=12)\n",
    "    x1 = 0 if xmin is None else xmin\n",
    "    x2 = max_x if xmax is None else xmax\n",
    "    y1 = 0 if ymin is None else ymin\n",
    "    y2 = max_y if ymax is None else ymax\n",
    "    \n",
    "    plt.ylim(y1, y2)\n",
    "    plt.xlim(x1, x2)\n",
    "    if aspect is not None:\n",
    "        plt.axes().set_aspect(aspect)\n",
    "    \n",
    "    plt.show()\n",
    "    #plt.colorbar(im, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(afloat):\n",
    "    new_str = f\"{afloat:.4f}\"\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json save and load\n",
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage: Using OrderTarceAlg to extract from the given spectral fits (for NEID or PARAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits_header = fits.open(spectral_fits)\n",
    "import pdb;pdb.set_trace()\n",
    "config_file = MODULE_DIR + 'configs/default.cfg'\n",
    "logger = start_logger(\"OrderTraceAlg\", config_file)\n",
    "\n",
    "width_p = 3\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "width_app = '_width_'+str(width_p) if width_p > 0 else '' \n",
    "\n",
    "order_t = OrderTraceAlg(fits_header[0].data, config, logger)\n",
    "\n",
    "if 'neid' in power_dir:\n",
    "    csv_file = 'neid_poly_3sigma_gaussian_pixel_' + str(power)+ width_app +'.csv'\n",
    "else:\n",
    "    csv_file = 'paras_poly_3sigma_gaussian_pixel_'+ str(power)+ width_app +'.csv'\n",
    "    \n",
    "imm_spec, nx, ny = order_t.get_spectral_data()\n",
    "cluster_info = order_t.extract_order_trace(power_for_width_estimation = width_p, show_time=True, print_debug='')\n",
    "output_df_to_csv  = result_csv;\n",
    "df = cluster_info['order_trace_result']\n",
    "df.to_csv(index=False, path_or_buf=output_df_to_csv, header=False)\n",
    "#order_t.write_cluster_info_to_csv(cluster_info['widths'], cluster_info['coeffs'], result_poly_width_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the order result and polynomial fits on top of the identified order\n",
    "new_x = cluster_info['cluster_x']\n",
    "new_y = cluster_info['cluster_y']\n",
    "new_index = cluster_info['cluster_index']\n",
    "_, nx, ny = order_t.get_spectral_data()\n",
    "\n",
    "cluster_imm = order_t.make_2d_data(new_index, new_x, new_y)\n",
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y)\n",
    "max_index = np.amax(new_index)\n",
    "\n",
    "print(np.shape(new_coeffs))\n",
    "print(max_index)\n",
    "plot_poly_trace(cluster_imm, max_index, new_coeffs, nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting order trace step by step\n",
    "### excute the cells from step 1 to step 7 and get visual output for each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load spectral file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_header = fits.open(spectral_fits)\n",
    "config_file = MODULE_DIR + 'configs/default.cfg'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "flat_data = fits_header[0].data\n",
    "total_row, total_col = np.shape(flat_data)\n",
    "order_t = OrderTraceAlg(flat_data, config)\n",
    "#order_t = OrderTraceAlg(flat_data[20:30, 20:30])\n",
    "#order_t = OrderTraceAlg(flat_data, config )\n",
    "imm_spec, nx, ny = order_t.get_spectral_data()\n",
    "spe_info = {'data': imm_spec, 'nx': nx, 'ny': ny}\n",
    "\n",
    "order_t.add_file_logger(\"\") \n",
    "print('row: ', spe_info['ny'], ' column: ', spe_info['nx'])\n",
    "plot_img(imm_spec, 0, ny-1)\n",
    "power = order_t.get_poly_degree()\n",
    "print('power: ', power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. locate_clusters() -- find cluster pixels  and make fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_xy = order_t.locate_clusters()\n",
    "yy = np.shape(cluster_xy['cluster_image'])[0]\n",
    "plot_img(cluster_xy['cluster_image'], 0, yy-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_cluster_info_csv(cluster_info_xy_csv, nx, ny, cluster_xy['x'], cluster_xy['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. form_clusters() or collect_clusters() + remove_cluster_by_size() + reorganize_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cluster_info, dict\n",
    "#cluster_info = order_t.collect_clusters(list(), list())\n",
    "cluster_info = order_t.collect_clusters(cluster_xy['x'], cluster_xy['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# assign index value to cluster_info['index'], where cluster_info['index'] is the same size as cluster_xy['x']\n",
    "cluster_info = order_t.remove_cluster_by_size(cluster_info, cluster_xy['x'], cluster_xy['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unassigned index\n",
    "x, y, index_r = order_t.reorganize_index(cluster_info['index'], cluster_xy['x'], cluster_xy['y'])\n",
    "imm = order_t.make_2d_data(index_r, x, y)   # show image  and make fits and info fits \n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save data from the result of 3 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm=make_cluster_fits(index_r, x, y, nx, ny, cluster_clean_fits)\n",
    "make_cluster_info_csv(cluster_info_clean_csv, nx, ny, x, y, index_r)\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload clean fits and info fits of step 3. (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) reload saved fits \n",
    "imm, hdr = fits.getdata(cluster_clean_fits, header=True)\n",
    "ny, nx = np.shape(imm)\n",
    "x, y, index_r = get_cluster_info_csv(cluster_info_clean_csv)\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. advanced_cluster_cleaning_handler() -- cluster cleaning to remove noisy clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_x, new_y, new_index, all_status = order_t.advanced_cluster_cleaning_handler(index_r, x, y)\n",
    "\n",
    "imm = order_t.make_2d_data(new_index, new_x, new_y)   # show image  and make fits and info fits \n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save advanced cleaning result of step 4 to fits and info fits (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_img(make_cluster_fits(new_index, new_x, new_y, nx, ny), 0, ny-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_advanced = make_cluster_fits(new_index, new_x, new_y, nx, ny, cluster_after_removal_fits)\n",
    "make_cluster_info_csv(cluster_info_after_removal_csv, nx, ny, new_x, new_y, new_index)\n",
    "\n",
    "plot_img(imm_advanced, 0, np.shape(imm_advanced)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload advanced cleaning results from result of step 4 (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imm_after_removal, hdr = fits.getdata(cluster_after_removal_fits, header=True)\n",
    "plot_img(new_imm_after_removal, 0, np.shape(new_imm_after_removal)[0]-1)\n",
    "new_x, new_y, new_index = get_cluster_info_csv(cluster_info_after_removal_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. clean_clusters_on_borders() or clean_clusters_on_border() for top and bottom border "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, index_b = order_t.clean_clusters_on_border(new_x, new_y, new_index, 0)\n",
    "print(len(new_index))\n",
    "print(len(index_b))\n",
    "\n",
    "new_x, new_y, new_index = order_t.clean_clusters_on_border(x, y, index_b, ny-1)\n",
    "print(len(index_b))\n",
    "print(len(new_index))\n",
    "imm = order_t.make_2d_data(new_index, new_x, new_y)   # show image  and make fits and info fits \n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  saving result of step 5 to fits and info fits (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_border = make_cluster_fits(new_index, new_x, new_y, nx, ny, cluster_border_fits)\n",
    "make_cluster_info_csv(cluster_info_border_csv, nx, ny, new_x, new_y, new_index)\n",
    "plot_img(imm_border, 0, ny-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload result of step 5 fits and info fits (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_border, hdr = fits.getdata(cluster_border_fits, header=True)\n",
    "plot_img(imm_border, 0, np.shape(imm_border)[0]-1)\n",
    "\n",
    "new_x, new_y, new_index = get_cluster_info_csv(cluster_info_border_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot order trace of step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for step 6\n",
    "imm_border = make_2D_data(new_index, new_x, new_y, nx, ny)\n",
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y)\n",
    "max_index = np.amax(new_index)\n",
    "\n",
    "print(np.shape(new_coeffs))\n",
    "print(max_index)\n",
    "plot_poly_trace(imm_border, max_index, new_coeffs, nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. merge_cluster() -  Merging clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_x, new_y, new_index = order_t.merge_clusters_and_clean(new_index, new_x, new_y)\n",
    "imm = order_t.make_2d_data(new_index, new_x, new_y)   # show image  and make fits and info fits \n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save merge results of step 6 to fits and info fits (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store after merge fits and fits info\n",
    "imm = make_cluster_fits(new_index, new_x, new_y, nx, ny, cluster_merge_fitting)\n",
    "make_cluster_info_csv(cluster_info_merge_fitting_csv, nx, ny, new_x, new_y, new_index)\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload merge result of step 6  (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm, hdr = fits.getdata(cluster_merge_fitting, header=True)\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)\n",
    "\n",
    "new_x, new_y, new_index = get_cluster_info_csv(cluster_info_merge_fitting_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot order trace of result of step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y)\n",
    "max_index = np.amax(new_index)    \n",
    "plot_poly_trace(imm, max_index, new_coeffs, nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. find_all_cluster_widths() -- find top and bottom widths of the orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_widths, cluster_coeffs =  order_t.find_all_cluster_widths(new_index, new_x, new_y, power_for_width_estimation=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output to Pandas dataframe and then to csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coeffs[:, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_poly_width_csv = result_csv\n",
    "order_t.write_cluster_info_to_csv(cluster_widths, cluster_coeffs, result_poly_width_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
