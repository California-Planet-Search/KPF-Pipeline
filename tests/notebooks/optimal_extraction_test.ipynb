{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from numpy.polynomial.polynomial import polyval, polyder\n",
    "import time\n",
    "import csv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import configparser\n",
    "import logging\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# sys.path.append('/Users/cwang/Documents/KPF/KPF-Pipeline/modules')\n",
    "%matplotlib inline\n",
    "\n",
    "class DotDict(dict):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.optimal_extraction.src.alg import OptimalExtractionAlg\n",
    "MODULE_DIR = '../../modules/optimal_extraction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tests.regression import test_optimal_extraction\n",
    "# add __init__.py tentatively for testing the following functions.\n",
    "test_optimal_extraction.test_init_exceptions()\n",
    "test_optimal_extraction.test_get_flux_from_order_exceptions()\n",
    "test_optimal_extraction.test_optimal_extraction_exceptions()\n",
    "test_optimal_extraction.test_get_flux_from_order_norect()\n",
    "test_optimal_extraction.test_get_flux_from_order_vertical()\n",
    "test_optimal_extraction.test_get_flux_from_order_normal()\n",
    "test_optimal_extraction.test_optimal_extraction_norect()\n",
    "test_optimal_extraction.test_optimal_extraction_vertical()\n",
    "test_optimal_extraction.test_optimal_extraction_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "TEST_DIR = os.getenv('KPFPIPE_TEST_DATA')\n",
    "print(TEST_DIR)\n",
    "KPF_PIPELINE = '/Users/cwang/documents/KPF/KPF-Pipeline/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of start_logger from logger.py\n",
    "def get_level(lvl:str) -> int:\n",
    "    if lvl == 'debug': return logging.DEBUG\n",
    "    elif lvl == 'info': return logging.INFO\n",
    "    elif lvl == 'warning': return logging.WARNING\n",
    "    elif lvl == 'error': return logging.ERROR\n",
    "    elif lvl == 'critical': return logging.CRITICAL\n",
    "    else: return logging.NOTSET\n",
    "    \n",
    "def start_logger(logger_name: str, config: str):\n",
    "    if config is None: \n",
    "        # a config file is not provided, so don't start logger\n",
    "        print('[{}] missing log configuration...not starting a new logger'.format(\n",
    "            logger_name))\n",
    "        return None\n",
    "    config_obj = configparser.ConfigParser()\n",
    "    res = config_obj.read(config)\n",
    "    if res == []:\n",
    "        return None\n",
    "\n",
    "    log_cfg = config_obj['LOGGER']\n",
    "\n",
    "    log_start = log_cfg.get('start_log', False)\n",
    "    log_path = log_cfg.get('log_path', 'log')\n",
    "    log_lvl = log_cfg.get('log_level', logging.WARNING)\n",
    "    log_verbose = log_cfg.getboolean('log_verbose', True)\n",
    "    # logger.setLevel(get_level(log_lvl))\n",
    "        \n",
    "    # if log_start:\n",
    "    #     # setup a log format\n",
    "    #     formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    #     # setup a log file\n",
    "    #     f_handle = logging.FileHandler(log_path, mode='w') # logging to file\n",
    "    #     f_handle.setLevel(get_level(log_lvl))\n",
    "    #     f_handle.setFormatter(formatter)\n",
    "    #     logger.addHandler(f_handle)\n",
    "\n",
    "    #     if log_verbose: \n",
    "    #         # also print to terminal \n",
    "    #         s_handle = logging.StreamHandler()\n",
    "    #         s_handle.setLevel(get_level(log_lvl))\n",
    "    #         s_handle.setFormatter(formatter)\n",
    "    #         logger.addHandler(s_handle)\n",
    "    # return logger\n",
    "\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(get_level(log_lvl))\n",
    "    logger.propagate = False\n",
    "\n",
    "    formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    s_handle = logging.StreamHandler()\n",
    "    s_handle.setLevel(get_level(log_lvl))\n",
    "    s_handle.setFormatter(formatter)\n",
    "    logger.addHandler(s_handle)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_fits_trace(spectral1, spectral2, total_rows, coeffs_rows, range_rows = None):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(1, 2, 1) \n",
    "    im1 = plt.imshow(spectral1['data'], cmap='gray', norm=LogNorm())\n",
    "\n",
    "    total_col = np.shape(coeffs_rows)[1]\n",
    "\n",
    "    for y in range(0, total_rows):\n",
    "        if range_rows is not None:\n",
    "            x_val = np.arange(range_rows[y, 0], range_rows[y, 1])\n",
    "        else:\n",
    "            x_val = np.arange(0, spectral['xdim'])\n",
    "        y_val = np.polyval(coeffs_rows[y], x_val)\n",
    "        plt.plot(x_val, y_val, 'r--')\n",
    "    \n",
    "    plt.ylim(0, spectral1['ydim'])\n",
    "    plt.colorbar(im1, fraction=0.046, pad=0.04)   \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    im2 = plt.imshow(spectral2['data'], cmap='gray', norm=LogNorm())\n",
    "    \n",
    "    plt.ylim(0, spectral2['ydim'])\n",
    "    plt.colorbar(im2, fraction=0.046, pad=0.04)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(out_data, total_rows):\n",
    "    # show output\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.imshow(out_data, cmap='gray')\n",
    "    plt.ylim(0, total_rows)\n",
    "    plt.show()\n",
    "    #plt.colorbar(im, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectral_sample(fits_file, order_trace_csv, flatlamp_file, config, logger, power):\n",
    "    spectrum_flux, spectrum_header = fits.getdata(fits_file, header=True)\n",
    "    print(flatlamp_file)\n",
    "    # import pdb;pdb.set_trace()\n",
    "    flat_flux = fits.open(flatlamp_file)\n",
    "    flat_idx = 1\n",
    "    if order_trace_csv is not None:\n",
    "        order_trace_result = np.genfromtxt(order_trace_csv, delimiter=',')  \n",
    "        order_trace_header = {'POLY_DEG': power}\n",
    "        flat_idx = 0\n",
    "    else:\n",
    "        order_trace_result =  pd.DataFrame(flat_flux[3].data)\n",
    "        order_trace_header = flat_flux[3].header\n",
    "        flat_idx = 1\n",
    "        \n",
    "            \n",
    "    print(type(spectrum_flux), type(spectrum_header))\n",
    "    print(type(order_trace_result), type(order_trace_header))\n",
    "    opt_extract = OptimalExtractionAlg(flat_flux[flat_idx].data, spectrum_flux, spectrum_header, \n",
    "                                       order_trace_result, order_trace_header, config, logger)\n",
    "    coeffs_rows = opt_extract.order_coeffs\n",
    "    widths = opt_extract.order_edges\n",
    "    xrange = opt_extract.order_xrange\n",
    "\n",
    "    # import pdb;pdb.set_trace()\n",
    "    spectral = {'data': spectrum_flux, 'xdim': int(spectrum_header['NAXIS1']), \n",
    "                                       'ydim': int(spectrum_header['NAXIS2'])}\n",
    "    flatlamp_spectral = {'data': flat_flux[flat_idx].data, 'xdim': int(flat_flux[flat_idx].header['NAXIS1']), \n",
    "                                                           'ydim': int(flat_flux[flat_idx].header['NAXIS2'])}        \n",
    "   \n",
    "    return {'spectral': spectral, 'flatlamp_spectral': flatlamp_spectral, 'coeffs': coeffs_rows,\n",
    "            'op_handle': opt_extract, 'widths': widths, 'xrange': xrange, 'power':power}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fits(data, output_fits, metadata):\n",
    "    # import pdb;pdb.set_trace()\n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    for key in metadata.keys():\n",
    "        hdu.header[key] = metadata[key]\n",
    "        \n",
    "    hdu.writeto(output_fits, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_optimal_trace(in_data, selected_order=None):\n",
    "    if selected_order is None:\n",
    "        height, width = np.shape(in_data)\n",
    "        selected_order = np.arange(0, height, dtype=int)\n",
    " \n",
    "    return in_data[selected_order, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 PARAS: define and load files: spectrum file, flat file, cure file, coeffs/width file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for PARAS data, from KPF-Pipeline-TestData/polygon_clipping_test/\n",
    "mission = 'PARAS'    # NEID or PARAS\n",
    "power = 4            # power = 4 if using csv from PARAS\n",
    "\n",
    "fits_base = TEST_DIR + '/polygon_clipping_test/paras_data/14feb2015/a00'\n",
    "fiber_list = ['A']\n",
    "f_idx = 0\n",
    "# flatlamp_file = TEST_DIR + '/polygon_clipping_test/paras_data/paras.flat'+fiber_list[f_idx]+'.fits'\n",
    "flatlamp_file = KPF_PIPELINE + 'test_results/paras/paras.flat'+fiber_list[f_idx]+'_L0.fits'\n",
    "fits_list=['18', '19']\n",
    "\n",
    "# csv from paras\n",
    "# csv_file =  TEST_DIR+'/polygon_clipping_test/paras_data/order_trace_'+fiber_list[f_idx]+'.csv'\n",
    "\n",
    "# csv from order trace module, paired with 'for_width_3' or 'for_fixed_width''\n",
    "# csv_file = TEST_DIR + '/order_trace_test/for_optimal_extraction/paras_poly_3sigma_gaussian_pixel_3_width_3.csv'\n",
    "# csv_file = TEST_DIR + '/order_trace_test/for_optimal_extraction/paras_poly_3sigma_gaussian_pixel_3.csv'\n",
    "power = 3\n",
    "width_type = 'for_width_3'                     # for using .csv from order trace, 'for_fixed_width', 'for_width_3'\n",
    "\n",
    "# optimal extraction method\n",
    "# method = OptimalExtractionAlg.NoRECT       # optimal extraction method: no rectified, \n",
    "# method = OptimalExtractionAlg.VERTICAL     # rectified using fractional summation in vertical direction\n",
    "method = OptimalExtractionAlg.NORMAL         # rectified using fractional summation in normal direction\n",
    "\n",
    "rectification_method = [ 'optimal_norm_fraction','optimal_vertical_fraction', 'optimal_not_rectified']\n",
    "\n",
    "output_base =  MODULE_DIR + 'results/PARAS_3sigma/' + width_type + '/PARAS_'    # temporarily output to a local directory\n",
    "# output for paras\n",
    "print('fits_base:', fits_base, '\\nflat file:', flatlamp_file, '\\noutput base:', output_base)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config_file = MODULE_DIR + 'configs/default.cfg'\n",
    "config.read(config_file)\n",
    "logger = start_logger(\"OptimalExtractionAlg\", config_file)\n",
    "csv_file = None  # order trace result is included in flatlamp_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is used to create the fits which contains the result of flux collection and optimal extraction from one order of one PARAS fits for the use of optimal extraction unit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flux_fits(order_flux, to_fits):\n",
    "\n",
    "    w = order_flux.get('data_width')\n",
    "    h = order_flux.get('data_height')\n",
    "    out_flux = np.zeros((h*2, w))\n",
    "    out_flux[0:h, :]=order_flux.get('order_data')\n",
    "    out_flux[h: , :]=order_flux.get('order_flat')\n",
    "    hdu = fits.PrimaryHDU(out_flux)\n",
    "    hdu.header\n",
    "        \n",
    "    hdu.writeto(to_fits, overwrite=True)\n",
    "    \n",
    "def get_flux_fits(flux_fits):\n",
    "    flux, header = fits.getdata(flux_fits, header=True)\n",
    "    w = header['NAXIS1']\n",
    "    h = header['NAXIS2']//2\n",
    "    order_data = flux[0:h, :]\n",
    "    order_flat = flux[h: , :]\n",
    "    return order_data, order_flat, h, w\n",
    "\n",
    "def get_flux_info_csv(file_path: str):\n",
    "    x = None\n",
    "    y = None\n",
    "    index = None\n",
    "    if os.path.isfile(file_path):\n",
    "        df = pd.read_csv(file_path, header=None, index_col=None)\n",
    "        row, col = np.shape(df.values)\n",
    "        data_h = col//2\n",
    "        data_w = row\n",
    "        order_data = np.transpose(df.values[:, 0:data_h])\n",
    "        order_flat = np.transpose(df.values[:, data_h:])\n",
    "    return order_data, order_flat, data_h, data_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits_file = fits_base + fits_list[0]+'.fits'\n",
    "csv_file = TEST_DIR + '/order_trace_test/for_optimal_extraction/paras_poly_3sigma_gaussian_pixel_3_width_3.csv'\n",
    "sample_info = load_spectral_sample(fits_file, csv_file, flatlamp_file, config, logger, power)\n",
    "test_row = 75\n",
    "c_set = np.array([test_row], dtype=int)\n",
    "poly_c = sample_info.get('op_handle')\n",
    "print(fits_file)\n",
    "\n",
    "c_order = c_set[0]\n",
    "order_flux = poly_c.get_flux_from_order(poly_c.order_coeffs[c_order], poly_c.get_order_edges(c_order),\n",
    "                                        poly_c.get_order_xrange(c_order), poly_c.spectrum_flux, poly_c.flat_flux,\n",
    "                                        norm_direction = method)\n",
    "\n",
    "print(np.shape(order_flux.get('order_data')))\n",
    "out_file = MODULE_DIR + 'results/PARAS_3sigma/paras_flux_'+rectification_method[method]+'.fits'\n",
    "print(\"flux file: \", out_file)\n",
    "make_flux_fits(order_flux, out_file)\n",
    "\n",
    "order_data, order_flat, data_height, data_width = get_flux_fits(out_file)\n",
    "  \n",
    "optimal_output = poly_c.optimal_extraction(order_data, order_flat, data_height, data_width)\n",
    "optimal_result = optimal_output['extraction'].flatten()  # result in Pandas Dataframe format\n",
    "\n",
    "hdu = fits.PrimaryHDU(optimal_result)\n",
    "out_file = MODULE_DIR+  'results/PARAS_3sigma/paras_extraction_'+rectification_method[method]+'.fits'\n",
    "hdu.writeto(out_file, overwrite=True)    \n",
    "print(\"optimal extraction file: \", out_file)\n",
    "\n",
    "target_file = MODULE_DIR + 'results/'+mission+'_3sigma/' + \\\n",
    "                  width_type +'/'+mission+'_' + fits_list[0] + '_extraction_'+ rectification_method[method] + '.fits'\n",
    "target_data = fits.open(target_file)\n",
    "target_optimal_result = target_data[0].data[test_row]\n",
    "    \n",
    "print('target_file: ', target_file)\n",
    "\n",
    "out_not_nan = np.argwhere(~np.isnan(optimal_result))\n",
    "target_not_nan = np.argwhere(~np.isnan(target_optimal_result))\n",
    "\n",
    "if np.size(out_not_nan) == np.size(target_not_nan):\n",
    "    if np.size(out_not_nan) != 0:\n",
    "        red_diff = target_optimal_result[target_not_nan] - optimal_result[out_not_nan]\n",
    "        non_zero_diff = np.where(red_diff != 0.0)\n",
    "        if (np.size(non_zero_diff) != 0):\n",
    "            print(non_zero_diff)\n",
    "        else:\n",
    "            print(\"same data\")\n",
    "else:\n",
    "    print(\"not the same NaN data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 NEID: define and load files: spectrum file, flat file, coeffs/width file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for NEID data\n",
    "mission = 'NEID'\n",
    "power = 3\n",
    "fits_base = TEST_DIR+'/NEIDdata/TAUCETI_20191217/L0/neidTemp_2D20191217T'\n",
    "flatlamp_file = TEST_DIR+'/NEIDdata/FLAT/stacked_2fiber_flat.fits'\n",
    "fits_list = ['023129', '023815','024240','024704', '025129', '025613', '030057','030724','031210','031636']\n",
    "\n",
    "csv_base = TEST_DIR+'/order_trace_test/for_optimal_extraction/'   \n",
    "# csv_file = csv_base + 'neid_poly_3sigma_gaussian_pixel_3.csv'        # paired with 'for_fixed_width'\n",
    "csv_file = csv_base + 'neid_poly_3sigma_gaussian_pixel_3_width_3.csv'  # paired with 'for_width_3'\n",
    "\n",
    "width_type = 'for_width_3'     #'for_fixed_width', 'for_width_3'\n",
    "\n",
    "# optimal extraction method\n",
    "method = OptimalExtractionAlg.NoRECT      # optimal extraction method: no rectified, \n",
    "# method = OptimalExtractionAlg.VERTICAL    # rectified using fractional summation in vertical direction\n",
    "# method = OptimalExtractionAlg.NORMAL      # rectified using fractional summation in normal direction\n",
    "\n",
    "rectification_method = [ 'optimal_norm_fraction','optimal_vertical_fraction', 'optimal_not_rectified']\n",
    "\n",
    "output_base = MODULE_DIR + 'results/NEID_3sigma/' + width_type + '/NEID_'      # temporarily output to a local directory \n",
    "\n",
    "# output for neid\n",
    "print('fits_base:', fits_base, '\\ncsv_file:', csv_file, '\\nflat file:', flatlamp_file, '\\noutput base:', output_base)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config_file = MODULE_DIR + 'configs/default.cfg'\n",
    "config.read(config_file)\n",
    "logger = start_logger(\"OptimalExtractionAlg\", config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal extraction (or sum fraction)  on a list of NEID/PARAS fits, create L1 output on original spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for f in range(0, len(fits_list)):\n",
    "#for f in range(1, 10):\n",
    "    fits_file = fits_base + fits_list[f]+'.fits'\n",
    "    \n",
    "    sample_info = load_spectral_sample(fits_file, csv_file, flatlamp_file, config, logger, power)\n",
    "    poly_c = sample_info.get('op_handle')\n",
    "\n",
    "    total_order = poly_c.get_spectrum_order()\n",
    "    if poly_c.get_instrument().upper() == 'NEID':\n",
    "        c_set = np.arange(0, total_order, poly_c.get_total_orderlettes(), dtype=int)\n",
    "    else:\n",
    "        c_set = None\n",
    "    \n",
    "    print(fits_file)\n",
    "    optimal_output = poly_c.extract_spectrum(rectification_method=method, extraction_method='optimal',\n",
    "                                             order_set=c_set, show_time=True, print_debug='')\n",
    "\n",
    "    optimal_result = optimal_output['optimal_extraction_result']    # result in Pandas Dataframe format\n",
    "    out_order_data = optimal_result.values\n",
    "    \n",
    "    plot_output(out_order_data, optimal_result.attrs['TOTALORD'])   # optimal extraction \n",
    "    \n",
    "    output_order_file = MODULE_DIR + 'results/'+mission+'_3sigma/'+width_type+'/'+mission+ '_' \\\n",
    "                        + fits_list[f] + '_extraction_' + rectification_method[method] + '.fits'\n",
    "    # make_fits(out_order_data, output_order_file, optimal_result.attrs )\n",
    "    \n",
    "    \n",
    "    nan_data = np.argwhere(np.isnan(out_order_data))\n",
    "    if (np.size(nan_data)>0):\n",
    "        print('there is pixel with nan data', nan_data)\n",
    "    else:\n",
    "        print('no pixel with nan data')\n",
    "    # compare the result to that before the porting\n",
    "    \n",
    "    \"\"\"\n",
    "    target_base = '/Users/cwang/documents/KPF/KPF-Pipeline/AlgorithmDev_07122020/test_data_04032020/'\n",
    "    target_file = target_base + 'order_trace_test/for_optimal_extraction/output/rv_'+mission+'_3sigma/' + \\\n",
    "                  width_type +'/'+mission+'_' + fits_list[f] + '_extraction_'+ rectification_method[method] + '.fits'\n",
    "    print('target_file: ', target_file)\n",
    "    target_data = fits.getdata(target_file)\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # for norect only\n",
    "    if mission == 'NEID':\n",
    "        # the following directory contain level 1 data from recipe running stored locally\n",
    "        target_file= '/Users/cwang/documents/KPF/KPF-Pipeline/test_results/neid/tmp/'+ \\\n",
    "             'stacked_2fiber_flat_L0_neidTemp_2D20191217T' + fits_list[f] + '_norect_L1.fits'\n",
    "       \n",
    "    else:\n",
    "        target_file = '/Users/cwang/documents/KPF/KPF-Pipeline/test_results/paras/tmp/' + \\\n",
    "            'paras.flatA_L0_a00' + fits_list[f] + '_norect_L1.fits'\n",
    "    \n",
    "    print('target_file: ', target_file)\n",
    "    target_hdu = fits.open(target_file)\n",
    "    target_data = target_hdu[1].data\n",
    "            \n",
    "    compare_result = poly_c.result_test(target_data, out_order_data)\n",
    "    if compare_result['result'] != 'ok':\n",
    "        print(compare_result['result'], compare_result['msg'])\n",
    "    else:\n",
    "        print(compare_result['result'])\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparison between NEID L1 and the result from module of optimal extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mission = 'NEID'\n",
    "method = OptimalExtractionAlg.VERTICAL\n",
    "width_type = 'for_width_3'\n",
    "rectification_method = [ 'optimal_norm_fraction','optimal_vertical_fraction', 'optimal_not_rectified']\n",
    "\n",
    "neid_L1_file = TEST_DIR + '/NEIDdata/TAUCETI_20191217/L1/neidL1_20191217T023129.fits'\n",
    "\n",
    "output_base =  MODULE_DIR + 'results/NEID_3sigma/' + width_type + '/'+mission+'_'  \n",
    "my_L1_file = output_base+'023129_extraction_'+ rectification_method[method] +'.fits'\n",
    "\n",
    "neid_L1_fits, neid_header = fits.getdata(neid_L1_file, header=True)\n",
    "my_L1_fits, my_header = fits.getdata(my_L1_file, header=True)\n",
    "                                   \n",
    "d = 7 \n",
    "neid_size = np.shape(neid_L1_fits)\n",
    "my_size = np.shape(my_L1_fits)\n",
    "total_avail = min(neid_size[0]-d, my_size[0])\n",
    "print('neid: ',np.shape(neid_L1_fits))\n",
    "print('my: ', np.shape(my_L1_fits))\n",
    "print('size_y: ', total_avail)\n",
    "\n",
    "x0 = 450\n",
    "\n",
    "center_x = input('center_x: ')\n",
    "c_x = center_x.strip()\n",
    "width = input('extension to the center: ')\n",
    "w_x = width.strip()\n",
    "\n",
    "c_x = int(c_x)\n",
    "w_x = int(w_x)\n",
    "s_x = max(x0, c_x - w_x)\n",
    "e_x = min(c_x+w_x, my_size[1])\n",
    "\n",
    "print('show x from ', s_x, ' to ', e_x)\n",
    "for i in np.arange(0, total_avail, dtype=int):\n",
    "    neid_order = neid_L1_fits[i+d, s_x:e_x]\n",
    "    my_order = my_L1_fits[i, s_x:e_x]\n",
    "\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(neid_order, 'b--', label='neid order: '+str(i+d))\n",
    "    plt.plot(my_order, 'r--', alpha=0.5, label = 'my order: ' + str(i))\n",
    "   \n",
    "    plt.title( '['+str(s_x)+','+str(e_x)+']')\n",
    "    plt.legend(loc=\"upper right\", prop={'size': 12})   \n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    ratio = (my_order-neid_order)/neid_order\n",
    "\n",
    "    abs_my = [ abs(i)  for i in my_order]\n",
    "    abs_neid = [abs(i) for i in neid_order]\n",
    "    ratio = np.absolute((my_order - neid_order)/np.maximum(abs_my, abs_neid))\n",
    "    plt.plot(ratio, 'g--', label='difference: ')\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
