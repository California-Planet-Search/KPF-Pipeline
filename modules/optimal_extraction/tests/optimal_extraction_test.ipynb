{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from numpy.polynomial.polynomial import polyval, polyder\n",
    "import time\n",
    "import csv\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import configparser\n",
    "import logging\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "class DotDict(dict):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.optimal_extraction.src import OptimalExtractionAlg\n",
    "load_dotenv()\n",
    "TEST_DIR = os.getenv('KPFPIPE_TEST_DATA')\n",
    "print(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of start_logger from logger.py\n",
    "def get_level(lvl:str) -> int:\n",
    "    if lvl == 'debug': return logging.DEBUG\n",
    "    elif lvl == 'info': return logging.INFO\n",
    "    elif lvl == 'warning': return logging.WARNING\n",
    "    elif lvl == 'error': return logging.ERROR\n",
    "    elif lvl == 'critical': return logging.CRITICAL\n",
    "    else: return logging.NOTSET\n",
    "    \n",
    "def start_logger(logger_name: str, config: str):\n",
    "    if config is None: \n",
    "        # a config file is not provided, so don't start logger\n",
    "        print('[{}] missing log configuration...not starting a new logger'.format(\n",
    "            logger_name))\n",
    "        return None\n",
    "    config_obj = configparser.ConfigParser()\n",
    "    res = config_obj.read(config)\n",
    "    if res == []:\n",
    "        return None\n",
    "\n",
    "    log_cfg = config_obj['LOGGER']\n",
    "\n",
    "    log_start = log_cfg.get('start_log', False)\n",
    "    log_path = log_cfg.get('log_path', 'log')\n",
    "    log_lvl = log_cfg.get('log_level', logging.WARNING)\n",
    "    log_verbose = log_cfg.getboolean('log_verbose', True)\n",
    "    # logger.setLevel(get_level(log_lvl))\n",
    "        \n",
    "    # if log_start:\n",
    "    #     # setup a log format\n",
    "    #     formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    #     # setup a log file\n",
    "    #     f_handle = logging.FileHandler(log_path, mode='w') # logging to file\n",
    "    #     f_handle.setLevel(get_level(log_lvl))\n",
    "    #     f_handle.setFormatter(formatter)\n",
    "    #     logger.addHandler(f_handle)\n",
    "\n",
    "    #     if log_verbose: \n",
    "    #         # also print to terminal \n",
    "    #         s_handle = logging.StreamHandler()\n",
    "    #         s_handle.setLevel(get_level(log_lvl))\n",
    "    #         s_handle.setFormatter(formatter)\n",
    "    #         logger.addHandler(s_handle)\n",
    "    # return logger\n",
    "\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(get_level(log_lvl))\n",
    "    logger.propagate = False\n",
    "\n",
    "    formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    s_handle = logging.StreamHandler()\n",
    "    s_handle.setLevel(get_level(log_lvl))\n",
    "    s_handle.setFormatter(formatter)\n",
    "    logger.addHandler(s_handle)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_two_fits_trace(spectral1, spectral2, total_rows, coeffs_rows, range_rows = None):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.subplot(1, 2, 1) \n",
    "    im1 = plt.imshow(spectral1['data'], cmap='gray', norm=LogNorm())\n",
    "\n",
    "    total_col = np.shape(coeffs_rows)[1]\n",
    "\n",
    "    for y in range(0, total_rows):\n",
    "        if range_rows is not None:\n",
    "            x_val = np.arange(range_rows[y, 0], range_rows[y, 1])\n",
    "        else:\n",
    "            x_val = np.arange(0, spectral['xdim'])\n",
    "        y_val = np.polyval(coeffs_rows[y], x_val)\n",
    "        plt.plot(x_val, y_val, 'r--')\n",
    "    \n",
    "    plt.ylim(0, spectral1['ydim'])\n",
    "    plt.colorbar(im1, fraction=0.046, pad=0.04)   \n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    im2 = plt.imshow(spectral2['data'], cmap='gray', norm=LogNorm())\n",
    "    \n",
    "    plt.ylim(0, spectral2['ydim'])\n",
    "    plt.colorbar(im2, fraction=0.046, pad=0.04)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(out_data, total_rows):\n",
    "    # show output\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.imshow(out_data, cmap='gray')\n",
    "    plt.ylim(0, total_rows)\n",
    "    plt.show()\n",
    "    #plt.colorbar(im, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spectral_sample(fits_file, order_trace_csv, flatlamp_file, config, logger, power):\n",
    "    spectrum_flux, spectrum_header = fits.getdata(fits_file, header=True)\n",
    "    flat_flux = fits.open(flatlamp_file)\n",
    "    order_trace_result = np.genfromtxt(order_trace_csv, delimiter=',')  \n",
    "    f_header = {'ORDER TRACE RESULT': {'POLY DEGREE': power}, 'PRIMARY': flat_flux[0].header}\n",
    "  \n",
    "    flat_data = DotDict() \n",
    "    flat_data.data = flat_flux[0].data\n",
    "    flat_data.order_trace_result = order_trace_result\n",
    "    flat_data.header = f_header\n",
    "    \n",
    "    spectrum_data = DotDict()\n",
    "    spectrum_data.data = spectrum_flux\n",
    "    spectrum_data.header = {'PRIMARY': spectrum_header}\n",
    "    \n",
    "\n",
    "    opt_extract = OptimalExtractionAlg(flat_data, spectrum_data, config, logger)\n",
    "    coeffs_rows = opt_extract.order_coeffs\n",
    "    widths = opt_extract.order_edges\n",
    "    xrange = opt_extract.order_xrange\n",
    "\n",
    "    spectral = {'data': spectrum_data.data, 'xdim': int(spectrum_data.header['PRIMARY']['NAXIS1']), \n",
    "                                            'ydim': int(spectrum_data.header['PRIMARY']['NAXIS2'])}\n",
    "    flatlamp_spectral = {'data': flat_data.data, 'xdim': int(flat_data.header['PRIMARY']['NAXIS1']), \n",
    "                                                 'ydim': int(flat_data.header['PRIMARY']['NAXIS2'])}\n",
    "   \n",
    "    return {'spectral': spectral, 'flatlamp_spectral': flatlamp_spectral, 'coeffs': coeffs_rows,\n",
    "            'op_handle': opt_extract, 'widths': widths, 'xrange': xrange, 'power':power}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fits(data, output_fits, metadata):\n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    for key in metadata.keys():\n",
    "        hdu.header[key] = metadata[key]\n",
    "        \n",
    "    hdu.writeto(output_fits, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_optimal_trace(in_data, selected_order=None):\n",
    "    if selected_order is None:\n",
    "        height, width = np.shape(in_data)\n",
    "        selected_order = np.arange(0, height, dtype=int)\n",
    " \n",
    "    return in_data[selected_order, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 PARAS: define and load files: spectrum file, flat file, cure file, coeffs/width file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for PARAS data, from KPF-Pipeline-TestData/polygon_clipping_test/\n",
    "mission = 'PARAS'    # NEID or PARAS\n",
    "power = 4            # power = 4 if using csv from PARAS\n",
    "\n",
    "fits_base = TEST_DIR + '/polygon_clipping_test/paras_data/14feb2015/a00'\n",
    "fiber_list = ['A']\n",
    "f_idx = 0\n",
    "flatlamp_file = TEST_DIR + '/polygon_clipping_test/paras_data/paras.flat'+fiber_list[f_idx]+'.fits'\n",
    "fits_list=['18', '19']\n",
    "\n",
    "# csv from paras\n",
    "# csv_file =  TEST_DIR+'/polygon_clipping_test/paras_data/order_trace_'+fiber_list[f_idx]+'.csv'\n",
    "\n",
    "# csv from order trace module, paired with 'for_width_3' or 'for_fixed_width''\n",
    "csv_file = TEST_DIR + '/order_trace_test/for_optimal_extraction/paras_poly_3sigma_gaussian_pixel_3_width_3.csv'\n",
    "# csv_file = TEST_DIR + '/order_trace_test/for_optimal_extraction/paras_poly_3sigma_gaussian_pixel_3.csv'\n",
    "power = 3\n",
    "width_type = 'for_width_3'                     # for using .csv from order trace, 'for_fixed_width', 'for_width_3'\n",
    "# width_type = fiber_list[f_idx]               # for using .csv from PARAS\n",
    "\n",
    "# optimal extraction method\n",
    "method = OptimalExtractionAlg.NoRECT       # optimal extraction method: no rectified, \n",
    "# method = OptimalExtractionAlg.VERTICAL     # rectified using fractional summation in vertical direction\n",
    "# method = OptimalExtractionAlg.NORMAL         # rectified using fractional summation in normal direction\n",
    "\n",
    "rectification_method = [ 'optimal_norm_fraction','optimal_vertical_fraction', 'optimal_not_rectified']\n",
    "\n",
    "output_base =  '../results/PARAS_3sigma/' + width_type + '/PARAS_'    # temporarily output to a local directory\n",
    "# output for neid\n",
    "print('fits_base:', fits_base, '\\ncsv_file:', csv_file, '\\nflat file:', flatlamp_file, '\\noutput base:', output_base)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config_file = '../configs/PARAS.cfg'\n",
    "config.read(config_file)\n",
    "logger = start_logger(\"OptimalExtractionAlg\", config_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 NEID: define and load files: spectrum file, flat file, coeffs/width file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for NEID data\n",
    "mission = 'NEID'\n",
    "power = 3\n",
    "fits_base = TEST_DIR+'/NEIDdata/TAUCETI_20191217/L0/neidTemp_2D20191217T'\n",
    "flatlamp_file = TEST_DIR+'/NEIDdata/FLAT/stacked_2fiber_flat.fits'\n",
    "fits_list = ['023129', '023815','024240','024704', '025129', '025613', '030057','030724','031210','031636']\n",
    "\n",
    "csv_base = TEST_DIR+'/order_trace_test/for_optimal_extraction/'   \n",
    "# csv_file = csv_base + 'neid_poly_3sigma_gaussian_pixel_3.csv'        # paired with 'for_fixed_width'\n",
    "csv_file = csv_base + 'neid_poly_3sigma_gaussian_pixel_3_width_3.csv'  # paired with 'for_width_3'\n",
    "\n",
    "width_type = 'for_width_3'     #'for_fixed_width', 'for_width_3'\n",
    "\n",
    "# optimal extraction method\n",
    "method = OptimalExtractionAlg.NoRECT      # optimal extraction method: no rectified, \n",
    "#method = OptimalExtractionAlg.VERTICAL    # rectified using fractional summation in vertical direction\n",
    "#method = OptimalExtractionAlg.NORMAL      # rectified using fractional summation in normal direction\n",
    "\n",
    "rectification_method = [ 'optimal_norm_fraction','optimal_vertical_fraction', 'optimal_not_rectified']\n",
    "\n",
    "output_base =  '../results/NEID_3sigma/' + width_type + '/NEID_'      # temporarily output to a local directory \n",
    "\n",
    "# output for neid\n",
    "print('fits_base:', fits_base, '\\ncsv_file:', csv_file, '\\nflat file:', flatlamp_file, '\\noutput base:', output_base)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config_file = '../configs/NEID.cfg'\n",
    "config.read(config_file)\n",
    "logger = start_logger(\"OptimalExtractionAlg\", config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal extraction (or sum fraction)  on a list of NEID/PARAS fits, create L1 output on original spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for f in range(0, len(fits_list)):\n",
    "#for f in range(1, 10):\n",
    "    fits_file = fits_base + fits_list[f]+'.fits'\n",
    "    sample_info = load_spectral_sample(fits_file, csv_file, flatlamp_file, config, logger, power)\n",
    "    poly_c = sample_info.get('op_handle')\n",
    "\n",
    "    total_order = poly_c.get_spectrum_order()\n",
    "    if mission == 'NEID':\n",
    "        c_set = np.arange(0, total_order, 2, dtype=int)\n",
    "    else:\n",
    "        c_set = None\n",
    "    # coeffs_rows = sample_info.get('coeffs')\n",
    "    # range_rows = sample_info.get('xrange')\n",
    "    # plot_two_fits_trace(spectral, flatlamp_spectral, np.shape(coeffs_rows)[0], coeffs_rows, range_rows)\n",
    "    \n",
    "    print(fits_file)\n",
    "    optimal_output = poly_c.extract_spectrum(rectification_method=method, extraction_method='optimal',\n",
    "                                             order_set=c_set, show_time=True, print_debug='result.txt')\n",
    "\n",
    "    optimal_result = optimal_output['optimal_extraction_result']    # result in Pandas Dataframe format\n",
    "    out_order_data = optimal_result.values\n",
    "    plot_output(out_order_data, optimal_result.attrs['TOTALORD'])   # optimal extraction \n",
    "    \n",
    "    output_order_file = '../results/'+mission+'_3sigma/'+width_type+'/'+mission+ '_' \\\n",
    "                        + fits_list[f] + '_extraction_' + rectification_method[method] + '.fits'\n",
    "    make_fits(out_order_data, output_order_file, optimal_result.attrs )\n",
    "    \n",
    "    nan_data = np.argwhere(np.isnan(out_order_data))\n",
    "    if np.size(nan_data) > 0:\n",
    "        print('there is pixel with nan data')\n",
    "    else:\n",
    "        print('no pixel with nan data')\n",
    "    # compare the result to that before the porting\n",
    "    target_base = '/Users/cwang/documents/KPF/KPF-Pipeline/AlgorithmDev/test_data_04032020/'\n",
    "    target_file = target_base + 'order_trace_test/for_optimal_extraction/output/rv_'+mission+'_3sigma/' + \\\n",
    "                  width_type +'/'+mission+'_' + fits_list[f] + '_extraction_'+ rectification_method[method] + '.fits'\n",
    "    print('target_file: ', target_file)\n",
    "    compare_result = poly_c.result_test(target_file, out_order_data)\n",
    "    print(compare_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparison between NEID L1 and the result from module of optimal extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mission = 'NEID'\n",
    "method = OptimalExtractionAlg.VERTICAL\n",
    "width_type = 'for_width_3'\n",
    "rectification_method = [ 'optimal_norm_fraction','optimal_vertical_fraction', 'optimal_not_rectified']\n",
    "\n",
    "neid_L1_file = TEST_DIR + '/NEIDdata/TAUCETI_20191217/L1/neidL1_20191217T023129.fits'\n",
    "\n",
    "output_base =  '../results/NEID_3sigma/' + width_type + '/'+mission+'_'  \n",
    "my_L1_file = output_base+'023129_extraction_'+ rectification_method[method] +'.fits'\n",
    "\n",
    "neid_L1_fits, neid_header = fits.getdata(neid_L1_file, header=True)\n",
    "my_L1_fits, my_header = fits.getdata(my_L1_file, header=True)\n",
    "                                   \n",
    "d = 7 \n",
    "neid_size = np.shape(neid_L1_fits)\n",
    "my_size = np.shape(my_L1_fits)\n",
    "total_avail = min(neid_size[0]-d, my_size[0])\n",
    "print('neid: ',np.shape(neid_L1_fits))\n",
    "print('my: ', np.shape(my_L1_fits))\n",
    "print('size_y: ', total_avail)\n",
    "\n",
    "x0 = 450\n",
    "\n",
    "center_x = input('center_x: ')\n",
    "c_x = center_x.strip()\n",
    "width = input('extension to the center: ')\n",
    "w_x = width.strip()\n",
    "\n",
    "c_x = int(c_x)\n",
    "w_x = int(w_x)\n",
    "s_x = max(x0, c_x - w_x)\n",
    "e_x = min(c_x+w_x, my_size[1])\n",
    "\n",
    "print('show x from ', s_x, ' to ', e_x)\n",
    "for i in np.arange(0, total_avail, dtype=int):\n",
    "    neid_order = neid_L1_fits[i+d, s_x:e_x]\n",
    "    my_order = my_L1_fits[i, s_x:e_x]\n",
    "\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(neid_order, 'b--', label='neid order: '+str(i+d))\n",
    "    plt.plot(my_order, 'r--', alpha=0.5, label = 'my order: ' + str(i))\n",
    "   \n",
    "    plt.title( '['+str(s_x)+','+str(e_x)+']')\n",
    "    plt.legend(loc=\"upper right\", prop={'size': 12})   \n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    ratio = (my_order-neid_order)/neid_order\n",
    "\n",
    "    abs_my = [ abs(i)  for i in my_order]\n",
    "    abs_neid = [abs(i) for i in neid_order]\n",
    "    ratio = np.absolute((my_order - neid_order)/np.maximum(abs_my, abs_neid))\n",
    "    plt.plot(ratio, 'g--', label='difference: ')\n",
    "    plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
