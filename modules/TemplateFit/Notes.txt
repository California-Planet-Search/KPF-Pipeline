--Observations--
1. use the different log levels:
    - log 'noop', 'exit_loop events' only on debug
    - log ERROR when a module is not found
2. import all required mod before execution.

--Concerns--


2. the flexibility issue of the framework is showing: 
    - I would argue that the framework is flexible on how 
    - primitves are defined, but quite strict on data flow 

--Quick Notes--
1. New framework Jan-2020 release:
    - big doc on multiprocessing and initiaization 

2. importing issues:
    The way our repository is setup makes the framework importation 
    quite inefficient: 
    - the path to each module can be specified in the framework config file
    - since our modules live in different folders, we need to add the module path 
    each time we create a module
    - this can be quite bad when there are alot of modules (overly long config)

2. How I am using the framework: 
    1. initialize framework and pipeline as usual 
    2. overwride logger and context class in pipeline instance 
    3. dynamically constructed event table and a module handle table
        - events always have ('mod_name', None, None) format
    4. setup an argument in the context class of the pipeline instance
        - argument is accessible to all events 
    5. pushed events onto queue directly

    - Issues with this: 
        1. cannot have a sequence of events, since we can only push onto queue
        in the beginning of the pipeline.

3. How framework is supposed to be used:
    1. initialize frameowrk and pipeline
        - looks like pipeline and framework still share same logger
    2. setup arguments and events, each event has its own deperate argument
    3. start framework. When a event finish, the next event is initialized and 
       pushed onto queue, with the previous event's output as input

    - It is still impossible to get if/else/for statements in recipe
      (The python recipe format cannot solve this since we cannot have access to 
       event output arguments in the pipeline)

4. goal: 
    1. we need to figure out a solution to the conditional recipes so that we can 
    bring it up in our next meeting with them 
    2. my goal now: clean up the dynamically updated event table with doc and 
    present to drp people next meeting 
    3. use the KPF data type in our modules
        - non-trivial since I created a customized HARPS data type when I started
        and all my code is built on top of that 
    
    It seems that it is quite counterproductive if we try to get a proper pipeline 
    setup (which is what I've been doing) since the frameowkr itself is constantly 
    being updated. 

    I propose that we devote less time to module/pipeline compatibility, and 
    more time on the core code of different modules. 
    - For example, the core of Templatefit is done. All it require now is pipeline 
      compatibility and tuning, which can be more efficiently done once the framework 
      and pipeline is actually done. 
    - spend time envisioning how our pipeline runs and create some prototypes for the DRP
      people (like conditions in recipe files)
    

