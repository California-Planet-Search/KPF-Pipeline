{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import math\n",
    "from scipy import ndimage, misc\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "import csv\n",
    "import pickle\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib import colors\n",
    "import configparser\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import logging\n",
    "%matplotlib inline\n",
    "power = 3\n",
    "# power_dir = \"output_neid_order_trace\"\n",
    "power_dir = \"output_paras_order_trace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.order_trace.src import OrderTraceAlg\n",
    "TEST_DIR = '/Users/cwang/documents/KPF/KPF-Pipeline/AlgorithmDev/test_data_04032020/'\n",
    "load_dotenv()\n",
    "KPF_TESTDATA = os.getenv('KPFPIPE_TEST_DATA')\n",
    "print(KPF_TESTDATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: spectral fits is from dropbox KPF-Pipeline-TestData/order_trace_test\n",
    "spectral_fits=  TEST_DIR + 'order_trace_test/DATA/paras.flatA.fits'\n",
    "\n",
    "# output\n",
    "clusters_collection = TEST_DIR + 'order_trace_test/'+power_dir+'/clusters_all_y_collection.pkl'\n",
    "cluster_xy_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_xy.fits'\n",
    "cluster_clean_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_clean.fits'\n",
    "cluster_info_clean_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_clean.fits'\n",
    "cluster_after_removal_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_after_removal.fits'\n",
    "cluster_info_after_removal_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_after_removal.fits'\n",
    "cluster_border_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_border.fits'\n",
    "cluster_info_border_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_border.fits'\n",
    "cluster_merge_fitting = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_merge_fitting.fits'\n",
    "cluster_info_merge_fitting = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_merging_fitting.fits'\n",
    "result_csv = TEST_DIR + 'order_trace_test/'+power_dir+'/result_cluster/result_cluster'\n",
    "result_poly_width_csv =  TEST_DIR + 'order_trace_test/'+power_dir+'/output/paras_result_poly_3sigma_gaussian_pixel_'+str(power)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: spectral fits is from dropbox KPF-Pipeline-TestData/NEIData/FLAT\n",
    "spectral_fits= KPF_TESTDATA + '/NEIDdata/FLAT/stacked_2fiber_flat.fits'\n",
    "\n",
    "# output\n",
    "clusters_collection = TEST_DIR + 'order_trace_test/'+power_dir+'/clusters_all_y_collection.pkl'\n",
    "remove_vertical_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/data_remove_vertical.fits'\n",
    "cluster_xy_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_xy.fits'\n",
    "cluster_clean_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_clean.fits'\n",
    "cluster_info_clean_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_clean.fits'\n",
    "cluster_after_removal_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_after_removal.fits'\n",
    "cluster_info_after_removal_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_after_removal.fits'\n",
    "cluster_border_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_border.fits'\n",
    "cluster_info_border_fits = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_border.fits'\n",
    "cluster_merge_fitting = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_merge_fitting.fits'\n",
    "cluster_info_merge_fitting = TEST_DIR + 'order_trace_test/'+power_dir+'/cluster_info_merging_fitting.fits'\n",
    "result_csv = TEST_DIR + 'order_trace_test/'+power_dir+'/result_cluster/result_cluster'\n",
    "result_poly_width_csv = TEST_DIR + 'order_trace_test/'+power_dir+'/output/neid_result_poly_3sigma_gaussian_pixel_'+str(power)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of start_logger from logger.py\n",
    "def get_level(lvl:str) -> int:\n",
    "    if lvl == 'debug': return logging.DEBUG\n",
    "    elif lvl == 'info': return logging.INFO\n",
    "    elif lvl == 'warning': return logging.WARNING\n",
    "    elif lvl == 'error': return logging.ERROR\n",
    "    elif lvl == 'critical': return logging.CRITICAL\n",
    "    else: return logging.NOTSET\n",
    "\n",
    "def start_logger(logger_name: str, config: str):\n",
    "    if config is None: \n",
    "        # a config file is not provided, so don't start logger\n",
    "        print('[{}] missing log configuration...not starting a new logger'.format(\n",
    "            logger_name))\n",
    "        return None\n",
    "    config_obj = configparser.ConfigParser()\n",
    "    res = config_obj.read(config)\n",
    "    if res == []:\n",
    "        return None\n",
    "\n",
    "    log_cfg = config_obj['LOGGER']\n",
    "\n",
    "    log_start = log_cfg.get('start_log', False)\n",
    "    log_path = log_cfg.get('log_path', 'log')\n",
    "    log_lvl = log_cfg.get('log_level', logging.WARNING)\n",
    "    log_verbose = log_cfg.getboolean('log_verbose', True)\n",
    "    # logger.setLevel(get_level(log_lvl))\n",
    "        \n",
    "    # if log_start:\n",
    "    #     # setup a log format\n",
    "    #     formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    #     # setup a log file\n",
    "    #     f_handle = logging.FileHandler(log_path, mode='w') # logging to file\n",
    "    #     f_handle.setLevel(get_level(log_lvl))\n",
    "    #     f_handle.setFormatter(formatter)\n",
    "    #     logger.addHandler(f_handle)\n",
    "\n",
    "    #     if log_verbose: \n",
    "    #         # also print to terminal \n",
    "    #         s_handle = logging.StreamHandler()\n",
    "    #         s_handle.setLevel(get_level(log_lvl))\n",
    "    #         s_handle.setFormatter(formatter)\n",
    "    #         logger.addHandler(s_handle)\n",
    "    # return logger\n",
    "\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "    logger.setLevel(get_level(log_lvl))\n",
    "    logger.propagate = False\n",
    "\n",
    "    formatter = logging.Formatter('[%(name)s][%(levelname)s]:%(message)s')\n",
    "    s_handle = logging.StreamHandler()\n",
    "    s_handle.setLevel(get_level(log_lvl))\n",
    "    s_handle.setFormatter(formatter)\n",
    "    logger.addHandler(s_handle)\n",
    "    return logger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_imshow(img):\n",
    "    if (np.amax(img) == 1) and (np.amin(img) == 0):\n",
    "        print('is bw image')\n",
    "        im = plt.imshow(img * -1, cmap='gray')\n",
    "    else:    \n",
    "        im = plt.imshow(img, cmap='gray', norm=LogNorm())\n",
    "    return im    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image from fits by setting area xmin, xmax, ymin, ymax\n",
    "def plot_img(img, ymin, ymax, p_w=20, p_h=20, xmin=None, xmax=None, title=\"\", aspect=None):\n",
    "    #if is_bw is True:\n",
    "    #    img = convert_to_bw(img)\n",
    "    plt.figure(figsize=(p_w, p_h), frameon=False)\n",
    "    plt.subplot(1, 1, 1)\n",
    "    if xmin is None:\n",
    "        xmin = 0\n",
    "    if xmax is None:\n",
    "        h, w = np.shape(img)\n",
    "        xmax = w-1\n",
    "    s_img = img[:, :]\n",
    "    im = plot_imshow(s_img)\n",
    "\n",
    "    #im = plt.imshow(s_img, cmap='gray')\n",
    "    plt.ylim(ymin, ymax)\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.title(title)\n",
    "    if aspect is not None:\n",
    "        plt.axes().set_aspect(aspect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fits(data, output_fits):\n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    hdu.writeto(output_fits, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make image data in 2D based on selected clusters\n",
    "def make_2D_data(index, x, y, nx, ny, selected_clusters=None):\n",
    "    imm = np.zeros((ny, nx), dtype=np.uint8)\n",
    "    \n",
    "    if selected_clusters is None:\n",
    "        selected_clusters = np.arange(1, np.amax(index)+1, dtype=int)\n",
    "\n",
    "    for idx in selected_clusters:\n",
    "        crt_idx = np.where(index == idx)[0]\n",
    "        imm[y[crt_idx], x[crt_idx]] = 1\n",
    "        \n",
    "    return imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fits on 2D of all clusters\n",
    "def make_cluster_fits(index, x, y, nx, ny, fits_path=None):\n",
    "    imm = make_2D_data(index, x, y,  nx, ny)\n",
    "    if fits_path is not None:\n",
    "        make_fits(imm, fits_path)\n",
    "    ind_max = np.amax(index)\n",
    "    print('there are '+str(ind_max)+' clusters in total in fits, '+fits_path)\n",
    "    return imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make fits on cluster info (index, x, y)\n",
    "def make_cluster_info_fits(index, x, y, cluster_info_filepath):\n",
    "    cluster_data = np.zeros((3, index.size))\n",
    "    cluster_data[0, :] = index\n",
    "    cluster_data[1, :] = x\n",
    "    cluster_data[2, :] = y\n",
    "    make_fits(cluster_data, cluster_info_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot polynomial fitting curve on top of given 2D image\n",
    "# the cluster orders is settable by order_set\n",
    "def plot_poly_trace(imm, total_order, coeffs_orders, max_x, max_y, size=20, order_set=None, \\\n",
    "                    title=None, background=False, widths=None, aspect=None, xmin=None, xmax=None, ymin=None, ymax=None):\n",
    "    plt.figure(figsize=(size,size))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    im = plot_imshow(imm)\n",
    "    #im = plt.imshow(imm, cmap='gray', norm=LogNorm())\n",
    "    \n",
    "    if order_set is None:\n",
    "        orders = list(range(1, total_order+1))\n",
    "    else:\n",
    "        orders = order_set\n",
    "        \n",
    "    x_dist = max_x//20    \n",
    "                   \n",
    "    for o_idx, order in enumerate(orders):\n",
    "        if (background is not False):\n",
    "            x_val = np.arange(0, max_x)\n",
    "            # y value on x range\n",
    "            y_val = np.polyval(coeffs_orders[order, 0:power+1], x_val)\n",
    "            plt.plot(x_val, y_val, 'b--')\n",
    "        #print(\"x range: \", coeffs_orders[order, power+1], coeffs_orders[order, power+2])    \n",
    "        # x range\n",
    "        x_val = np.arange(coeffs_orders[order, power+1], coeffs_orders[order, power+2]+1)\n",
    "        # y value on x range\n",
    "        y_val = np.polyval(coeffs_orders[order, 0:power+1], x_val)\n",
    "        plt.plot(x_val, y_val, 'r--')\n",
    "        \n",
    "        if widths is not None:\n",
    "            y_val_bottom = y_val-widths[o_idx][0]\n",
    "            plt.plot(x_val, y_val_bottom, 'g--')\n",
    "            y_val_top = y_val+widths[o_idx][1]\n",
    "            plt.plot(x_val, y_val_top, 'g--')\n",
    "        \n",
    "        # show number of cluster\n",
    "        s = ((order%15)+1)*x_dist\n",
    "        if s >= x_val.size:\n",
    "            dem = int((coeffs_orders[order, power+2] - coeffs_orders[order, power+1])//5)\n",
    "            s = dem*((order%4)+1)\n",
    "            #s = x_val.size//2\n",
    "        plt.text(x_val[s], y_val[s], str(order), fontsize=12, color='b', fontweight='bold', horizontalalignment='center', verticalalignment='center')\n",
    "        \n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=12)\n",
    "    x1 = 0 if xmin is None else xmin\n",
    "    x2 = max_x if xmax is None else xmax\n",
    "    y1 = 0 if ymin is None else ymin\n",
    "    y2 = max_y if ymax is None else ymax\n",
    "    \n",
    "    plt.ylim(y1, y2)\n",
    "    plt.xlim(x1, x2)\n",
    "    if aspect is not None:\n",
    "        plt.axes().set_aspect(aspect)\n",
    "    \n",
    "    plt.show()\n",
    "    #plt.colorbar(im, fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(afloat):\n",
    "    new_str = f\"{afloat:.4f}\"\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json save and load\n",
    "def save_obj(obj, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage: Using OrderTarceAlg to extract from the given spectral fits (for NEID or PARAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits_header = fits.open(spectral_fits)\n",
    "config_file = \"/Users/cwang/documents/KPF/KPF-Pipeline/modules/order_trace/configs/default.cfg\"\n",
    "logger = start_logger(\"OrderTraceAlg\", config_file)\n",
    "\n",
    "width_p = 3\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "width_app = '_width_'+str(width_p) if width_p > 0 else '' \n",
    "\n",
    "order_t = OrderTraceAlg(fits_header[0].data, config, logger)\n",
    "\n",
    "if 'neid' in power_dir:\n",
    "    csv_file = 'neid_poly_3sigma_gaussian_pixel_' + str(power)+ width_app +'.csv'\n",
    "else:\n",
    "    csv_file = 'paras_poly_3sigma_gaussian_pixel_'+ str(power)+ width_app +'.csv'\n",
    "    \n",
    "imm_spec, nx, ny = order_t.get_spectral_data()\n",
    "cluster_info = order_t.extract_order_trace(power_for_width_estimation = width_p, show_time=True, print_debug='')\n",
    "output_df_to_csv  = TEST_DIR + 'order_trace_test/'+power_dir+'/output/'+ csv_file;\n",
    "df = cluster_info['order_trace_result']\n",
    "df.to_csv(index=False, path_or_buf=output_df_to_csv, header=False)\n",
    "#order_t.write_cluster_info_to_csv(cluster_info['widths'], cluster_info['coeffs'], result_poly_width_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the order result and polynomial fits on top of the identified order\n",
    "new_x = cluster_info['cluster_x']\n",
    "new_y = cluster_info['cluster_y']\n",
    "new_index = cluster_info['cluster_index']\n",
    "_, nx, ny = order_t.get_spectral_data()\n",
    "\n",
    "cluster_imm = order_t.make_2d_data(new_index, new_x, new_y)\n",
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y)\n",
    "max_index = np.amax(new_index)\n",
    "\n",
    "print(np.shape(new_coeffs))\n",
    "print(max_index)\n",
    "plot_poly_trace(cluster_imm, max_index, new_coeffs, nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting order trace step by step\n",
    "### excute the cells from step 1 to step 10 and get visual output for each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. load spectral file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fits_header = fits.open(spectral_fits)\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "if 'neid' in power_dir:\n",
    "    config.read('../configs/NEID.cfg')\n",
    "else:\n",
    "    config.read('../configs/PARAS.cfg')\n",
    "\n",
    "order_t = OrderTraceAlg(fits_header[0].data, config )\n",
    "order_t.enable_debug_print()\n",
    "imm_spec, nx, ny = order_t.get_spectral_data()\n",
    "spe_info = {'data': imm_spec, 'nx': nx, 'ny': ny}\n",
    "print('row: ', spe_info['ny'], ' column: ', spe_info['nx'])\n",
    "plot_img(imm_spec, 0, ny-1)\n",
    "power = order_t.get_poly_degree()\n",
    "print('power: ', power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. find cluster pixels  and make fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_xy = order_t.locate_clusters()\n",
    "yy = np.shape(cluster_xy['cluster_image'])[0]\n",
    "plot_img(cluster_xy['cluster_image'], 0, yy-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. form clusters, basic cleanning (based on size and total pixel), make fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#cluster_info, dict\n",
    "cluster_info = order_t.collect_clusters(cluster_xy['x'], cluster_xy['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(cluster_info, clusters_collection)   # optional, save cluster info into .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) load cluster collection \n",
    "cluster_info = load_obj(clusters_collection)   # optional, load cluster info from .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# assign index value to cluster_info['index'], where cluster_info['index'] is the same size as cluster_xy['x']\n",
    "cluster_info = order_t.remove_cluster_by_size(cluster_info, cluster_xy['x'], cluster_xy['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unassigned index\n",
    "x, y, index_r = order_t.reorganize_index(cluster_info['index'], cluster_xy['x'], cluster_xy['y'])\n",
    "nx = spe_info['nx']\n",
    "ny = spe_info['ny']\n",
    "imm = order_t.make_2d_data(index_r, x, y)   # show image  and make fits and info fits \n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save data from the result of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm=make_cluster_fits(index_r, x, y, nx, ny, cluster_clean_fits)\n",
    "make_cluster_info_fits(index_r, x, y, cluster_info_clean_fits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reload clean fits and info fits of step 3. (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) reload saved fits \n",
    "imm, hdr = fits.getdata(cluster_clean_fits, header=True)\n",
    "ny, nx = np.shape(imm)\n",
    "cluster_info, c_hdr = fits.getdata(cluster_info_clean_fits, header=True)\n",
    "index_r = cluster_info[0].astype(int)\n",
    "x = cluster_info[1].astype(int)\n",
    "y = cluster_info[2].astype(int)\n",
    "\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)\n",
    "ind_max = np.amax(index_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Advanced cluster cleaning to remove noisy clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "index_adv, all_status = order_t.advanced_cluster_cleaning_handler(index_r, x, y)\n",
    "\n",
    "# prepare for saving\n",
    "x_p = x.copy()\n",
    "y_p = y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save advanced cleaning result of step 4 to fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x, new_y, new_index = order_t.reorganize_index(index_adv, x_p, y_p)\n",
    "imm_advanced = make_cluster_fits(new_index, new_x, new_y, nx, ny, cluster_after_removal_fits)\n",
    "make_cluster_info_fits(new_index, new_x, new_y, cluster_info_after_removal_fits)\n",
    "\n",
    "plot_img(imm_advanced, 0, np.shape(imm_advanced)[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) load advanced cleaning results, result of step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imm_after_removal, hdr = fits.getdata(cluster_after_removal_fits, header=True)\n",
    "plot_img(new_imm_after_removal, 0, np.shape(new_imm_after_removal)[0]-1)\n",
    "\n",
    "cluster_info_tmp, c_hdr = fits.getdata(cluster_info_after_removal_fits, header=True)\n",
    "new_index = cluster_info_tmp[0].astype(int)\n",
    "new_x = cluster_info_tmp[1].astype(int)\n",
    "new_y = cluster_info_tmp[2].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. clean the clusters along the top and bottom border (optional), new_x, new_y, new_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_r = new_index.copy()\n",
    "x = new_x.copy()\n",
    "y = new_y.copy()\n",
    "\n",
    "x, y, index_b = order_t.clean_clusters_on_border(x, y, index_r, 0)\n",
    "print(len(index_r))\n",
    "print(len(index_b))\n",
    "\n",
    "x, y, index_t = order_t.clean_clusters_on_border(x, y, index_b, ny-1)\n",
    "new_x, new_y, new_index= order_t.reorganize_index(index_t, x, y)\n",
    "print(len(index_b))\n",
    "print(len(new_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saving result of step 5 to fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_border = make_cluster_fits(new_index, new_x, new_y, nx, ny, cluster_border_fits)\n",
    "make_cluster_info_fits(new_index, new_x, new_y, cluster_info_border_fits)\n",
    "plot_img(imm_border, 0, ny-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) load result of step 5 fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm_border, hdr = fits.getdata(cluster_border_fits, header=True)\n",
    "plot_img(imm_border, 0, np.shape(imm_border)[0]-1)\n",
    "\n",
    "cluster_info, c_hdr = fits.getdata(cluster_info_border_fits, header=True)\n",
    "new_index = cluster_info[0].astype(int)\n",
    "new_x = cluster_info[1].astype(int)\n",
    "new_y = cluster_info[2].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data for step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for step 6\n",
    "imm_border = make_2D_data(new_index, new_x, new_y, nx, ny)\n",
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y)\n",
    "max_index = np.amax(new_index)\n",
    "\n",
    "print(np.shape(new_coeffs))\n",
    "print(max_index)\n",
    "plot_poly_trace(imm_border, max_index, new_coeffs, nx, ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Merging clusters, input parameters:  index_t, x, y, imm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_x, m_y, m_index, m_coeffs = order_t.merge_clusters(new_index, new_x, new_y)\n",
    "#m_x, m_y, m_index, m_coeffs = merge_clusters(new_index, new_x, new_y, power)\n",
    "new_x = m_x.copy()\n",
    "new_y = m_y.copy()\n",
    "new_index = m_index.copy()\n",
    "new_coeffs = m_coeffs.copy()\n",
    "\n",
    "max_index = np.amax(new_index)\n",
    "plot_poly_trace(imm_border, max_index, new_coeffs, nx, ny, title='after merging cluster', size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save merge results of step 6 to fits and info fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store after merge fits and fits info\n",
    "imm = make_cluster_fits(new_index, new_x, new_y, nx, ny, cluster_merge_fitting)\n",
    "make_cluster_info_fits(new_index, new_x, new_y, cluster_info_merge_fitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_coeffs = new_coeffs\n",
    "cluster_points = order_t.get_cluster_points(new_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) load merge result of step 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imm, hdr = fits.getdata(cluster_merge_fitting, header=True)\n",
    "plot_img(imm, 0, np.shape(imm)[0]-1)\n",
    "\n",
    "cluster_info, c_hdr = fits.getdata(cluster_info_merge_fitting, header=True)\n",
    "new_index = cluster_info[0].astype(int)\n",
    "new_x = cluster_info[1].astype(int)\n",
    "new_y = cluster_info[2].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot on result of step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index, new_x, new_y)\n",
    "max_index = np.amax(new_index)    \n",
    "plot_poly_trace(imm, max_index, new_coeffs, nx, ny)\n",
    "cluster_points = order_t.get_cluster_points(new_coeffs)\n",
    "cluster_coeffs = new_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.  remove broken cluster which has big opening in the center (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x1, new_y1, new_index1 = order_t.remove_broken_cluster(new_index, new_x, new_y)\n",
    "next_coeffs, errors = order_t.curve_fitting_on_all_clusters(new_index1, new_x1, new_y1)\n",
    "imm =  make_2D_data(new_index1, new_x1, new_y1, nx, ny)\n",
    "max_index = np.amax(new_index1)\n",
    "\n",
    "plot_poly_trace(imm, max_index, next_coeffs, nx, ny, title='after removing broken cluster', size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = new_x1.copy()\n",
    "new_y = new_y1.copy()\n",
    "new_index = new_index1.copy()\n",
    "cluster_points = order_t.get_cluster_points(next_coeffs)\n",
    "cluster_coeffs = next_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. (optional) fitting clusters on peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_cluster_no = np.amax(new_index)\n",
    "original_coeffs = cluster_coeffs.copy()\n",
    "peak_info = order_t.curve_fitting_on_peaks(cluster_coeffs)\n",
    "plot_poly_trace(imm, max_cluster_no, peak_info['coeffs'], nx, ny, title=\"fitting on cluster peaks\", size=20)\n",
    "cluster_points = peak_info['peak_pixels']\n",
    "cluster_coeffs =  peak_info['coeffs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(peak_info['errors'], np.mean(peak_info['errors']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (optional) difference (RMS) between peak fitting and cluster pixel fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = order_t.rms_of_polys(original_coeffs, peak_info['coeffs'], power)\n",
    "print(rms, np.mean(rms))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. call API to find width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cluster_widths =  order_t.find_all_cluster_widths(new_index, cluster_coeffs,cluster_points, \n",
    "                                                  power_for_width_estimation=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### order trace output:  output to Pandas dataframe and then to csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = order_t.write_cluster_info_to_dataframe(cluster_widths, cluster_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "csvfile = TEST_DIR + 'order_trace_test/'+power_dir+'/output/neid_poly_3sigma_gaussian_pixel_'+str(power)+'_pandas.csv'\n",
    "df.to_csv(index=False, path_or_buf=csvfile, sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### order trace output to csv file directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_poly_width_csv = TEST_DIR + 'order_trace_test/'+power_dir+'/output/neid_poly_3sigma_gaussian_pixel_'+str(power)+'_width_3.csv'\n",
    "order_t.write_cluster_info_to_csv(cluster_widths, cluster_coeffs, result_poly_width_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
